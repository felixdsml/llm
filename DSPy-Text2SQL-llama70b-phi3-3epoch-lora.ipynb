{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llama-3-8b-Instruct-bnb-4bit-synthetic_text_to_sql-lora-3epochs-Q5_K_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\llm\\llm-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from dspy.datasets import DataLoader\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch, LabeledFewShot\n",
    "\n",
    "#from src.starling import StarlingLM # <- Custom Local Model Client for llama3-8b\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that will be used in this notebook is [llama3-8b](https://huggingface.co/Nexusflow/Starling-LM-7B-beta), and the evaluation model will be [GPT-4 Turbo](https://openai.com/gpt-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share generation args between models\n",
    "generation_args = {\n",
    "    \"temperature\":0,\n",
    "    \"max_tokens\":500,\n",
    "    \"stop\":\"\\n\\n\",\n",
    "    \"model_type\":\"chat\",\n",
    "    \"n\": 1\n",
    "}\n",
    "# Model specific args\n",
    "model_info = {\n",
    "    \"gpt-4\": {\"model\": \"gpt-4-0125-preview\", \"api_base\": \"https://api.openai.com/v1/\"},\n",
    "    \"starling\": {\"model\": \"Nexusflow/Starling-LM-7B-beta\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the models\n",
    "# lm = StarlingLM(**model_info[\"starling\"], **generation_args)\n",
    "# evaluator_lm = dspy.OpenAI(**model_info[\"gpt-4\"], **generation_args)\n",
    "\n",
    "lm = dspy.OllamaLocal(model=\"Phi-3-medium-4k-instruct-synthetic_text_to_sql-lora-3epochs-q5_k_m:latest\", base_url='http://localhost:11435')\n",
    "# evaluator_lm = dspy.OpenAI(**model_info[\"gpt-4\"], **generation_args)\n",
    "evaluator_lm = dspy.OllamaLocal(model='llama3:70b', base_url='http://localhost:11434')\n",
    "\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bogot√°.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing inference of Starling\n",
    "lm(\"What is the capital of Colombia?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that will be used in this notebook is [gretelai/synthetic_text_to_sql](https://huggingface.co/datasets/gretelai/synthetic_text_to_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random seed\n",
    "random.seed(1399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load dataset\n",
    "# dl = DataLoader()\n",
    "# trainset = dl.from_huggingface(\n",
    "#     dataset_name=\"gretelai/synthetic_text_to_sql\", # Dataset name from Huggingface\n",
    "#     fields=(\"sql_prompt\", \"sql_context\", \"sql\"), # Fields needed\n",
    "#     input_keys=(\"sql_prompt\", \"sql_context\"), # What our model expects to recieve to generate an output\n",
    "#     split=\"train\"\n",
    "# )\n",
    "\n",
    "# testset = dl.from_huggingface(\n",
    "#     dataset_name=\"gretelai/synthetic_text_to_sql\", # Dataset name from Huggingface\n",
    "#     fields=(\"sql_prompt\", \"sql_context\", \"sql\"), # Fields needed\n",
    "#     input_keys=(\"sql_prompt\", \"sql_context\"), # What our model expects to recieve to generate an output\n",
    "#     split=\"test\"\n",
    "# )\n",
    "\n",
    "\n",
    "# trainset = dl.sample(dataset=trainset, n=100)\n",
    "# testset = dl.sample(dataset=testset, n=75)\n",
    "# finetuneset = dl.sample(dataset=trainset, n=100)\n",
    "\n",
    "# _trainval = dl.train_test_split(dataset=trainset, test_size=0.25, random_state=1399) # 25% of training data for validation\n",
    "# trainset, valset = _trainval[\"train\"], _trainval[\"test\"]\n",
    "\n",
    "# len(trainset), len(valset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 40 80\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dl = DataLoader()\n",
    "\n",
    "testset = dl.from_huggingface(\n",
    "    dataset_name=\"gretelai/synthetic_text_to_sql\", # Dataset name from Huggingface\n",
    "    fields=(\"sql_prompt\", \"sql_context\", \"sql\"), # Fields needed\n",
    "    input_keys=(\"sql_prompt\", \"sql_context\"), # What our model expects to recieve to generate an output\n",
    "    split=\"test\"\n",
    ")\n",
    "# print(len(testset))\n",
    "\n",
    "testset = dl.sample(dataset=testset, n=200)\n",
    "\n",
    "# Calculate the sizes of each set\n",
    "total_size = len(testset)\n",
    "train_size = int(total_size * 0.4)  # 40% of the data\n",
    "val_size = int(total_size * 0.2)  # 20% of the data\n",
    "\n",
    "# Split the dataset into train, validation and test sets\n",
    "trainset = testset[:train_size]\n",
    "valset = testset[train_size:train_size + val_size]\n",
    "testset = testset[train_size + val_size:]\n",
    "\n",
    "print(len(trainset), len(valset), len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL_PROMPT:\n",
      "\n",
      "What is the average monthly data usage for each mobile network operator?\n",
      "\n",
      "SQL_CONTEXT:\n",
      "\n",
      "CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);\n",
      "\n",
      "SQL:\n",
      "\n",
      "SELECT o.operator_name, AVG(u.usage_amount) AS avg_monthly_data_usage FROM mobile_operators o INNER JOIN mobile_plans p ON o.operator_id = p.operator_id INNER JOIN usage u ON p.plan_id = u.plan_id WHERE u.usage_date >= DATEADD(month, -1, GETDATE()) GROUP BY o.operator_name;\n"
     ]
    }
   ],
   "source": [
    "# Verify an example of the dataset\n",
    "sample = trainset[0]\n",
    "for k, v in sample.items():\n",
    "    print(f\"\\n{k.upper()}:\\n\")\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify an example of the dataset\n",
    "# sample = dl.sample(dataset=trainset, n=1)[0]\n",
    "# for k, v in sample.items():\n",
    "#     print(f\"\\n{k.upper()}:\\n\")\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signature (Input/Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextToSql(dspy.Signature):\n",
    "    \"\"\"Transform a natural language query into a SQL query.\"\"\"\n",
    "\n",
    "    sql_prompt = dspy.InputField(desc=\"Natural language query\")\n",
    "    sql_context = dspy.InputField(desc=\"Context for the query\")\n",
    "    sql = dspy.OutputField(desc=\"SQL query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL:\n",
      "\n",
      "SELECT mo.operator_name, AVG(u.usage_amount) as avg_data_usage FROM mobile_operators mo JOIN mobile_plans mp ON mo.operator_id = mp.operator_id JOIN usage u ON mp.plan_id = u.plan_id GROUP BY mo.operator_name;\n"
     ]
    }
   ],
   "source": [
    "generate_sql_query = dspy.Predict(signature=TextToSql)\n",
    "\n",
    "result = generate_sql_query(\n",
    "    sql_prompt=sample[\"sql_prompt\"],\n",
    "    sql_context=sample[\"sql_context\"]\n",
    ")\n",
    "\n",
    "for k, v in result.items():\n",
    "    print(f\"\\n{k.upper()}:\\n\")\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChainOfThought Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RATIONALE:\n",
      "\n",
      "CREATE VIEW avg_monthly_data_usage AS SELECT mobile_plans.operator_id, AVG(usage_amount / 12) as avg_monthly_data_usage FROM usage JOIN mobile_plans ON usage.plan_id = mobile_plans.plan_id GROUP BY mobile_plans.operator_id;\n",
      "\n",
      "SQL:\n",
      "\n",
      "CREATE VIEW avg_monthly_data_usage AS SELECT mobile_plans.operator_name, AVG(usage_amount / 12) as avg_monthly_data_usage FROM usage JOIN mobile_plans ON usage.plan_id = mobile_plans.plan_id GROUP BY mobile_plans.operator_name;\n"
     ]
    }
   ],
   "source": [
    "generate_sql_query = dspy.ChainOfThought(signature=TextToSql)\n",
    "\n",
    "result = generate_sql_query(\n",
    "    sql_prompt=sample[\"sql_prompt\"],\n",
    "    sql_context=sample[\"sql_context\"]\n",
    ")\n",
    "\n",
    "for k, v in result.items():\n",
    "    print(f\"\\n{k.upper()}:\\n\")\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric of evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Correctness(dspy.Signature):\n",
    "    \"\"\"Assess if the SQL query accurately answers the given natural language query based on the provided context.\"\"\"\n",
    "\n",
    "    sql_prompt = dspy.InputField(desc=\"Natural language query \")\n",
    "    sql_context = dspy.InputField(desc=\"Context for the query\")\n",
    "    sql = dspy.InputField(desc=\"SQL query\")\n",
    "    correct = dspy.OutputField(desc=\"Indicate whether the SQL query correctly answers the natural language query based on the given context\", prefix=\"Yes/No:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness_metric(example, pred, trace=None):\n",
    "    sql_prompt, sql_context, sql = example.sql_prompt, example.sql_context, pred.sql\n",
    "\n",
    "    correctness = dspy.Predict(Correctness)\n",
    "\n",
    "    with dspy.context(lm=evaluator_lm): \n",
    "        correct = correctness(\n",
    "            sql_prompt=sql_prompt,\n",
    "            sql_context=sql_context,\n",
    "            sql=sql,\n",
    "        )\n",
    "    \n",
    "    score = int(correct.correct==\"Yes\")\n",
    "\n",
    "    if trace is not None:\n",
    "        return score == 1\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct SQL query: Yes\n"
     ]
    }
   ],
   "source": [
    "_correctness = correctness_metric(\n",
    "    example=sample,\n",
    "    pred=result\n",
    ")\n",
    "print(f\"Correct SQL query: {'Yes' if _correctness else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Assess if the SQL query accurately answers the given natural language query based on the provided context.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Sql Prompt: Natural language query\n",
      "\n",
      "Sql Context: Context for the query\n",
      "\n",
      "Sql: SQL query\n",
      "\n",
      "Yes/No: Indicate whether the SQL query correctly answers the natural language query based on the given context\n",
      "\n",
      "---\n",
      "\n",
      "Sql Prompt: What is the average monthly data usage for each mobile network operator?\n",
      "\n",
      "Sql Context: CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);\n",
      "\n",
      "Sql: CREATE VIEW avg_monthly_data_usage AS SELECT mobile_plans.operator_name, AVG(usage_amount / 12) as avg_monthly_data_usage FROM usage JOIN mobile_plans ON usage.plan_id = mobile_plans.plan_id GROUP BY mobile_plans.operator_name;\n",
      "\n",
      "Yes/No: Yes\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nAssess if the SQL query accurately answers the given natural language query based on the provided context.\\n\\n---\\n\\nFollow the following format.\\n\\nSql Prompt: Natural language query\\n\\nSql Context: Context for the query\\n\\nSql: SQL query\\n\\nYes/No: Indicate whether the SQL query correctly answers the natural language query based on the given context\\n\\n---\\n\\nSql Prompt: What is the average monthly data usage for each mobile network operator?\\n\\nSql Context: CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);\\n\\nSql: CREATE VIEW avg_monthly_data_usage AS SELECT mobile_plans.operator_name, AVG(usage_amount / 12) as avg_monthly_data_usage FROM usage JOIN mobile_plans ON usage.plan_id = mobile_plans.plan_id GROUP BY mobile_plans.operator_name;\\n\\nYes/No:\\x1b[32m Yes\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate entire dataset - GPT 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #F0F0F0; padding: 10px; border-radius: 5px;\"> <p style=\"color: #4B4B4B; font-size: 18px; font-weight: bold; margin: 0;\"> üìä Baseline Evaluation </p> <p style=\"color: #4B4B4B; font-size: 16px; margin: 5px 0 0;\"> Without any optimization, <strong>Starling7B</strong> achieves an <strong>80% correctness in validation (25 samples)</strong> and <strong>70.07% correctness in test (75 samples).</strong> </p> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPT 3.5 Turbo - Validation Score: \\n\")\n",
    "with dspy.context(lm=dspy.OpenAI(model=\"gpt-3.5-turbo-0125\", api_base=\"https://api.openai.com/v1/\", **generation_args)):\n",
    "    evaluate = Evaluate(devset=valset, metric=correctness_metric, num_threads=10, display_progress=True, display_table=0)\n",
    "    evaluate(generate_sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPT 3.5 Turbo - Test Score: \\n\")\n",
    "with dspy.context(lm=dspy.OpenAI(model=\"gpt-3.5-turbo-0125\", api_base=\"https://api.openai.com/v1/\", **generation_args)):\n",
    "    evaluate = Evaluate(devset=testset, metric=correctness_metric, num_threads=10, display_progress=True, display_table=0)\n",
    "    evaluate(generate_sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate entire dataset - llama3-8b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFCCCB; padding: 10px; border-radius: 5px;\"> <p style=\"color: #8B0000; font-size: 18px; font-weight: bold; margin: 0;\"> ‚ö†Ô∏è Evaluation Stage 1 </p> <p style=\"color: #8B0000; font-size: 16px; margin: 5px 0 0;\"> Without any optimization, <strong>llama3-8b</strong> achieves an <strong>72% correctness in validation (25 samples)</strong> and <strong>50.67% correctness in test (75 samples).</strong> </p> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8b - Validation Score: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 15 / 40  (37.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [03:33<00:00,  5.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"llama3-8b - Validation Score: \\n\")\n",
    "evaluate = Evaluate(devset=valset, metric=correctness_metric, num_threads=10, display_progress=True, display_table=0)\n",
    "evaluate(generate_sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8b - Test Score: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 80  (35.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [06:31<00:00,  4.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"llama3-8b - Test Score: \\n\")\n",
    "evaluate = Evaluate(devset=testset, metric=correctness_metric, num_threads=10, display_progress=True, display_table=0)\n",
    "evaluate(generate_sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize for Text2SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the program ~ You can think of this a Pytorch model.\n",
    "class TextToSqlProgram(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.program = dspy.ChainOfThought(signature=TextToSql)\n",
    "    \n",
    "    def forward(self, sql_prompt, sql_context):\n",
    "        return self.program(\n",
    "            sql_prompt=sql_prompt,\n",
    "            sql_context=sql_context\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FewShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the optimizer -> this only adds few shots to the prompt\n",
    "optimizer = LabeledFewShot(k=4)\n",
    "optmized_program = optimizer.compile(student=TextToSqlProgram(), trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    rationale='Sql Prompt: What is the average monthly data usage for each mobile network operator?\\nSql Context: CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);',\n",
       "    sql='SELECT mo.operator_name, AVG(u.usage_amount) AS mobile? What is the average monthly data usage for each mobile network operator?\\n\\nSql Context: CREATE TABLE mobile_operators ('\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optmized_program(sql_context=sample[\"sql_context\"], sql_prompt=sample[\"sql_prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is happening inside?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Transform a natural language query into a SQL query.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Sql Prompt: Natural language query\n",
      "\n",
      "Sql Context: Context for the query\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the sql}. We ...\n",
      "\n",
      "Sql: SQL query\n",
      "\n",
      "---\n",
      "\n",
      "Sql Prompt: How many solar power projects were completed in California and Texas in 2020 and 2021?\n",
      "Sql Context: CREATE TABLE solar_projects (project_id INT, state VARCHAR(50), completion_year INT); INSERT INTO solar_projects (project_id, state, completion_year) VALUES (1, 'California', 2020), (2, 'Texas', 2021), (3, 'California', 2019), (4, 'Texas', 2020), (5, 'California', 2021), (6, 'Texas', 2019), (7, 'California', 2018), (8, 'Texas', 2018);\n",
      "Sql: SELECT state, COUNT(*) FROM solar_projects WHERE completion_year IN (2020, 2021) AND state IN ('California', 'Texas') GROUP BY state;\n",
      "\n",
      "---\n",
      "\n",
      "Sql Prompt: What is the sum of lanthanum imports to Norway and Sweden for the years 2018 and 2019?\n",
      "Sql Context: CREATE TABLE lanthanum_imports (year INT, country TEXT, quantity INT); INSERT INTO lanthanum_imports (year, country, quantity) VALUES (2018, 'Norway', 150), (2019, 'Norway', 160), (2018, 'Sweden', 140), (2019, 'Sweden', 150);\n",
      "Sql: SELECT SUM(quantity) FROM lanthanum_imports WHERE country IN ('Norway', 'Sweden') AND year IN (2018, 2019);\n",
      "\n",
      "---\n",
      "\n",
      "Sql Prompt: List all cases where the client is from 'California' and the attorney is 'Smith'\n",
      "Sql Context: CREATE TABLE cases (case_id INT, client_state VARCHAR(2), attorney_name VARCHAR(20));\n",
      "Sql: SELECT * FROM cases WHERE client_state = 'CA' AND attorney_name = 'Smith';\n",
      "\n",
      "---\n",
      "\n",
      "Sql Prompt: What is the total number of labor rights advocacy events for each region, by region name?\n",
      "Sql Context: CREATE TABLE Region (Id INT, Name VARCHAR(50)); INSERT INTO Region (Id, Name) VALUES (1, 'Region A'), (2, 'Region B'), (3, 'Region C'); CREATE TABLE AdvocacyEvents (Id INT, RegionId INT, EventCount INT); INSERT INTO AdvocacyEvents (Id, RegionId, EventCount) VALUES (1, 1, 50), (2, 1, 30), (3, 2, 70), (4, 2, 80), (5, 3, 60), (6, 3, 40);\n",
      "Sql: SELECT R.Name, SUM(A.EventCount) as TotalEvents FROM Region R JOIN AdvocacyEvents A ON R.Id = A.RegionId GROUP BY R.Name;\n",
      "\n",
      "---\n",
      "\n",
      "Sql Prompt: What is the average monthly data usage for each mobile network operator?\n",
      "\n",
      "Sql Context: CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);\n",
      "\n",
      "Reasoning: Let's think step by step in order to Sql Prompt: What is the average monthly data usage for each mobile network operator?\n",
      "Sql Context: CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);\n",
      "Sql: SELECT mo.operator_name, AVG(u.usage_amount) AS mobile? What is the average monthly data usage for each mobile network operator?\n",
      "\n",
      "Sql Context: CREATE TABLE mobile_operators (\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nTransform a natural language query into a SQL query.\\n\\n---\\n\\nFollow the following format.\\n\\nSql Prompt: Natural language query\\n\\nSql Context: Context for the query\\n\\nReasoning: Let's think step by step in order to ${produce the sql}. We ...\\n\\nSql: SQL query\\n\\n---\\n\\nSql Prompt: How many solar power projects were completed in California and Texas in 2020 and 2021?\\nSql Context: CREATE TABLE solar_projects (project_id INT, state VARCHAR(50), completion_year INT); INSERT INTO solar_projects (project_id, state, completion_year) VALUES (1, 'California', 2020), (2, 'Texas', 2021), (3, 'California', 2019), (4, 'Texas', 2020), (5, 'California', 2021), (6, 'Texas', 2019), (7, 'California', 2018), (8, 'Texas', 2018);\\nSql: SELECT state, COUNT(*) FROM solar_projects WHERE completion_year IN (2020, 2021) AND state IN ('California', 'Texas') GROUP BY state;\\n\\n---\\n\\nSql Prompt: What is the sum of lanthanum imports to Norway and Sweden for the years 2018 and 2019?\\nSql Context: CREATE TABLE lanthanum_imports (year INT, country TEXT, quantity INT); INSERT INTO lanthanum_imports (year, country, quantity) VALUES (2018, 'Norway', 150), (2019, 'Norway', 160), (2018, 'Sweden', 140), (2019, 'Sweden', 150);\\nSql: SELECT SUM(quantity) FROM lanthanum_imports WHERE country IN ('Norway', 'Sweden') AND year IN (2018, 2019);\\n\\n---\\n\\nSql Prompt: List all cases where the client is from 'California' and the attorney is 'Smith'\\nSql Context: CREATE TABLE cases (case_id INT, client_state VARCHAR(2), attorney_name VARCHAR(20));\\nSql: SELECT * FROM cases WHERE client_state = 'CA' AND attorney_name = 'Smith';\\n\\n---\\n\\nSql Prompt: What is the total number of labor rights advocacy events for each region, by region name?\\nSql Context: CREATE TABLE Region (Id INT, Name VARCHAR(50)); INSERT INTO Region (Id, Name) VALUES (1, 'Region A'), (2, 'Region B'), (3, 'Region C'); CREATE TABLE AdvocacyEvents (Id INT, RegionId INT, EventCount INT); INSERT INTO AdvocacyEvents (Id, RegionId, EventCount) VALUES (1, 1, 50), (2, 1, 30), (3, 2, 70), (4, 2, 80), (5, 3, 60), (6, 3, 40);\\nSql: SELECT R.Name, SUM(A.EventCount) as TotalEvents FROM Region R JOIN AdvocacyEvents A ON R.Id = A.RegionId GROUP BY R.Name;\\n\\n---\\n\\nSql Prompt: What is the average monthly data usage for each mobile network operator?\\n\\nSql Context: CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);\\n\\nReasoning: Let's think step by step in order to\\x1b[32m Sql Prompt: What is the average monthly data usage for each mobile network operator?\\nSql Context: CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);\\nSql: SELECT mo.operator_name, AVG(u.usage_amount) AS mobile? What is the average monthly data usage for each mobile network operator?\\n\\nSql Context: CREATE TABLE mobile_operators (\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the optimized program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: #FFF8DC; padding: 10px; border-radius: 5px;\"> <p style=\"color: #DAA520; font-size: 18px; font-weight: bold; margin: 0;\"> üåü Evaluation Stage 2 </p> <p style=\"color: #DAA520; font-size: 16px; margin: 5px 0 0;\"> With <strong>Few Shot</strong> optimization, <strong>llama3-8b</strong> achieves an <strong>64% correctness in validation (25 samples)</strong> and <strong>60% correctness in test (75 samples).</strong> </p> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8b + FewShotOptimizer - Validation Score: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 40  (67.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [02:45<00:00,  4.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"llama3-8b + FewShotOptimizer - Validation Score: \\n\")\n",
    "evaluate = Evaluate(devset=valset, metric=correctness_metric, num_threads=10, display_progress=True, display_table=0)\n",
    "evaluate(optmized_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8b + FewShotOptimizer - Test Score: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 38 / 80  (47.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [05:49<00:00,  4.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"llama3-8b + FewShotOptimizer - Test Score: \\n\")\n",
    "evaluate = Evaluate(devset=testset, metric=correctness_metric, num_threads=10, display_progress=True, display_table=0)\n",
    "evaluate(optmized_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BootstrapFewShotWithRandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DSPy docs](https://dspy-docs.vercel.app/docs/building-blocks/optimizers) recommend that in a setup like the one with have at hand, with ~50 samples, the best option is to use `BootstrapFewShotWithRandomSearch`:\n",
    "\n",
    "![image](assets/dspy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 40  (42.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [03:30<00:00,  5.26s/it]\n",
      "Average Metric: 25 / 40  (62.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [02:47<00:00,  4.18s/it]\n",
      "  5%|‚ñå         | 4/80 [01:01<19:33, 15.45s/it]\n",
      "Average Metric: 25 / 40  (62.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [02:54<00:00,  4.35s/it]\n",
      "  4%|‚ñç         | 3/80 [00:40<17:19, 13.50s/it]\n",
      "Average Metric: 23 / 40  (57.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [02:54<00:00,  4.35s/it]\n",
      "  1%|‚ñè         | 1/80 [00:09<13:09,  9.99s/it]\n",
      "Average Metric: 29 / 40  (72.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [02:29<00:00,  3.75s/it]\n",
      "  2%|‚ñé         | 2/80 [00:26<17:18, 13.32s/it]\n",
      "Average Metric: 26 / 40  (65.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [02:51<00:00,  4.29s/it]\n",
      "  1%|‚ñè         | 1/80 [00:11<14:48, 11.25s/it]\n",
      "Average Metric: 23 / 40  (57.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [03:12<00:00,  4.82s/it]\n",
      "  2%|‚ñé         | 2/80 [00:23<15:21, 11.82s/it]\n",
      "Average Metric: 24 / 40  (60.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [03:00<00:00,  4.51s/it]\n",
      "  2%|‚ñé         | 2/80 [00:21<14:09, 10.89s/it]\n",
      "Average Metric: 24 / 40  (60.0): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [02:50<00:00,  4.27s/it]\n",
      "  1%|‚ñè         | 1/80 [00:11<15:22, 11.68s/it]\n",
      "Average Metric: 25 / 40  (62.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [02:52<00:00,  4.31s/it]\n",
      "  5%|‚ñå         | 4/80 [01:00<19:06, 15.08s/it]\n",
      "Average Metric: 27 / 40  (67.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [03:02<00:00,  4.57s/it]\n"
     ]
    }
   ],
   "source": [
    "optimizer2 = BootstrapFewShotWithRandomSearch(metric=correctness_metric, max_bootstrapped_demos=2, num_candidate_programs=8, num_threads=5)\n",
    "optmized_program_2 = optimizer2.compile(student = TextToSqlProgram(), trainset=trainset, valset=valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    rationale='Sql: SELECT m.operator_name, AVG(u.usage_amount) as avg_monthly_data_usage FROM mobile_operators m INNER JOIN mobile_plans mp ON m.operator_id = mp.operator_id INNER JOIN usage u ON mp.plan_id = u.plan_id GROUP BY m.operator_name;',\n",
       "    sql='SELECT m.operator_name, AVG(u.usage_amount) as avg_monthly_data_usage FROM mobile_operators m INNER JOIN mobile_plans mp ON m.operator_id = mp.operator_id INNER JOIN usage u ON mp.plan_id = u.plan_id GROUP BY m.operator_name;'\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optmized_program_2(sql_context=sample[\"sql_context\"], sql_prompt=sample[\"sql_prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Transform a natural language query into a SQL query.\n",
      "\n",
      "---\n",
      "\n",
      "Sql Prompt: What is the total number of labor rights advocacy events for each region, by region name?\n",
      "Sql Context: CREATE TABLE Region (Id INT, Name VARCHAR(50)); INSERT INTO Region (Id, Name) VALUES (1, 'Region A'), (2, 'Region B'), (3, 'Region C'); CREATE TABLE AdvocacyEvents (Id INT, RegionId INT, EventCount INT); INSERT INTO AdvocacyEvents (Id, RegionId, EventCount) VALUES (1, 1, 50), (2, 1, 30), (3, 2, 70), (4, 2, 80), (5, 3, 60), (6, 3, 40);\n",
      "Sql: SELECT R.Name, SUM(A.EventCount) as TotalEvents FROM Region R JOIN AdvocacyEvents A ON R.Id = A.RegionId GROUP BY R.Name;\n",
      "\n",
      "Sql Prompt: Find and delete duplicate records in the resource_depletion table\n",
      "Sql Context: CREATE TABLE resource_depletion (id INT, resource VARCHAR(255), depletion_rate DECIMAL(10,2));\n",
      "Sql: DELETE t1 FROM resource_depletion t1 INNER JOIN (SELECT id, resource, depletion_rate, COUNT(*) FROM resource_depletion GROUP BY resource, depletion_rate HAVING COUNT(*) > 1) t2 ON t1.resource = t2.resource AND t1.depletion_rate = t2.depletion_rate AND t1.id < t2.id;\n",
      "\n",
      "Sql Prompt: What are the AI safety principles and their corresponding descriptions?\n",
      "Sql Context: CREATE TABLE ai_safety_principles (principle_id INTEGER, principle_name TEXT, principle_description TEXT);\n",
      "Sql: SELECT principle_name, principle_description FROM ai_safety_principles;\n",
      "\n",
      "Sql Prompt: Find the supplier with the lowest average delivery time for orders in the last month.\n",
      "Sql Context: CREATE TABLE Suppliers (SupplierID int, SupplierName varchar(50)); CREATE TABLE Products (ProductID int, ProductName varchar(50), SupplierID int); CREATE TABLE Orders (OrderID int, ProductID int, OrderDate date, DeliveryTime int); INSERT INTO Suppliers VALUES (1, 'SupplierA'), (2, 'SupplierB'); INSERT INTO Products VALUES (1, 'Organic Apples', 1), (2, 'Bananas', 2); INSERT INTO Orders VALUES (1, 1, '2022-01-01', 2), (2, 2, '2022-01-03', 3);\n",
      "Sql: SELECT SupplierName, AVG(DeliveryTime) as AvgDeliveryTime FROM Orders o JOIN Products p ON o.ProductID = p.ProductID JOIN Suppliers sp ON p.SupplierID = sp.SupplierID WHERE OrderDate >= DATEADD(month, -1, GETDATE()) GROUP BY SupplierName ORDER BY AvgDeliveryTime ASC;\n",
      "\n",
      "Sql Prompt: What is the total number of peacekeeping operations conducted by each country, ranked from highest to lowest?\n",
      "Sql Context: CREATE TABLE PeacekeepingOperations (Country VARCHAR(50), Year INT, Operations INT); INSERT INTO PeacekeepingOperations (Country, Year, Operations) VALUES ('USA', 2020, 15), ('China', 2020, 10), ('France', 2020, 12), ('USA', 2021, 18), ('China', 2021, 14), ('France', 2021, 16);\n",
      "Sql: SELECT Country, SUM(Operations) OVER (PARTITION BY Country ORDER BY Year ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS TotalOperations, RANK() OVER (ORDER BY SUM(Operations) DESC) AS PeacekeepingRank FROM PeacekeepingOperations GROUP BY Country ORDER BY PeacekeepingRank;\n",
      "\n",
      "Sql Prompt: What is the minimum temperature reading for sensor with ID 102 in the 'sensors' table?\n",
      "Sql Context: CREATE TABLE sensors (id INT, sensor_id INT, temperature DECIMAL(5,2)); INSERT INTO sensors (id, sensor_id, temperature) VALUES (1, 101, 23.5), (2, 102, 25.7), (3, 103, 21.8), (4, 104, 27.3);\n",
      "Sql: SELECT MIN(temperature) FROM sensors WHERE sensor_id = 102;\n",
      "\n",
      "Sql Prompt: What is the average number of employees for companies in the 'Technology' industry, categorized by founding year?\n",
      "Sql Context: CREATE TABLE Company_Info (company_name VARCHAR(50), industry VARCHAR(20), employee_count INT); INSERT INTO Company_Info (company_name, industry, employee_count) VALUES ('Waystar Royco', 'Media', 5000); INSERT INTO Company_Info (company_name, industry, employee_count) VALUES ('Pied Piper', 'Technology', 50); INSERT INTO Company_Info (company_name, industry, employee_count) VALUES ('Austin Biotech', 'Biotechnology', 250); INSERT INTO Company_Info (company_name, industry, employee_count) VALUES ('Everest Technologies', 'Technology', 100);\n",
      "Sql: SELECT founding_year, AVG(employee_count) FROM (SELECT company_name, CASE WHEN industry = 'Technology' THEN founding_year END as founding_year, employee_count FROM Company_Info) t GROUP BY founding_year;\n",
      "\n",
      "Sql Prompt: Find the number of students who received accommodations in the \"Online Learning\" category\n",
      "Sql Context: CREATE TABLE accommodations (student_id INT, accommodation_category VARCHAR(20)); INSERT INTO accommodations (student_id, accommodation_category) VALUES (1, 'Online Learning'), (2, 'Exam'), (3, 'Note Taking');\n",
      "Sql: SELECT COUNT(*) FROM accommodations WHERE accommodation_category = 'Online Learning';\n",
      "\n",
      "Sql Prompt: What is the average transaction amount for retail customers in New York?\n",
      "Sql Context: CREATE TABLE retail_customers (customer_id INT, name VARCHAR(50), state VARCHAR(20), transaction_amount DECIMAL(10,2)); INSERT INTO retail_customers (customer_id, name, state, transaction_amount) VALUES (1, 'John Doe', 'NY', 120.50), (2, 'Jane Smith', 'NY', 75.30);\n",
      "Sql: SELECT AVG(transaction_amount) FROM retail_customers WHERE state = 'NY';\n",
      "\n",
      "Sql Prompt: What is the average age of female fans who prefer the 'Soccer' team in the 'fan_demographics' table?\n",
      "Sql Context: CREATE TABLE fan_demographics (id INT PRIMARY KEY, name VARCHAR(100), gender VARCHAR(10), age INT, favorite_team VARCHAR(50)); CREATE TABLE teams (id INT PRIMARY KEY, name VARCHAR(100), sport VARCHAR(50));\n",
      "Sql: SELECT AVG(fd.age) as avg_age FROM fan_demographics fd JOIN teams t ON fd.favorite_team = t.name WHERE fd.gender = 'Female' AND t.name = 'Soccer';\n",
      "\n",
      "Sql Prompt: What is the sum of lanthanum imports to Norway and Sweden for the years 2018 and 2019?\n",
      "Sql Context: CREATE TABLE lanthanum_imports (year INT, country TEXT, quantity INT); INSERT INTO lanthanum_imports (year, country, quantity) VALUES (2018, 'Norway', 150), (2019, 'Norway', 160), (2018, 'Sweden', 140), (2019, 'Sweden', 150);\n",
      "Sql: SELECT SUM(quantity) FROM lanthanum_imports WHERE country IN ('Norway', 'Sweden') AND year IN (2018, 2019);\n",
      "\n",
      "Sql Prompt: What is the maximum daily water usage in MWh for the industrial sector in October 2021?\n",
      "Sql Context: CREATE TABLE max_daily_water_usage (year INT, month INT, sector VARCHAR(20), day INT, usage FLOAT); INSERT INTO max_daily_water_usage (year, month, sector, day, usage) VALUES (2021, 10, 'industrial', 1, 8000); INSERT INTO max_daily_water_usage (year, month, sector, day, usage) VALUES (2021, 10, 'industrial', 2, 8500); INSERT INTO max_daily_water_usage (year, month, sector, day, usage) VALUES (2021, 10, 'industrial', 3, 9000);\n",
      "Sql: SELECT MAX(usage) FROM max_daily_water_usage WHERE year = 2021 AND month = 10 AND sector = 'industrial';\n",
      "\n",
      "Sql Prompt: What is the distribution of security incidents by day of the week for the last year?\n",
      "Sql Context: CREATE TABLE security_incidents_by_day (day_of_week VARCHAR(10), incident_count INT, incident_date DATE); INSERT INTO security_incidents_by_day (day_of_week, incident_count, incident_date) VALUES ('Monday', 120, '2022-01-01'), ('Tuesday', 140, '2022-01-02'), ('Wednesday', 160, '2022-01-03'), ('Thursday', 130, '2022-01-04'), ('Friday', 110, '2022-01-05');\n",
      "Sql: SELECT DATENAME(dw, incident_date) AS day_of_week, COUNT(*) AS incident_count FROM security_incidents WHERE incident_date >= DATEADD(year, -1, GETDATE()) GROUP BY DATENAME(dw, incident_date);\n",
      "\n",
      "Sql Prompt: List the names of all sensors and their respective locations from the 'sensor_data' and 'sensor_location' tables\n",
      "Sql Context: CREATE TABLE sensor_data (sensor_id INT, water_level FLOAT, timestamp TIMESTAMP); CREATE TABLE sensor_location (sensor_id INT, location VARCHAR(50));\n",
      "Sql: SELECT sensor_data.sensor_id, sensor_location.location FROM sensor_data INNER JOIN sensor_location ON sensor_data.sensor_id = sensor_location.sensor_id;\n",
      "\n",
      "Sql Prompt: What is the number of companies founded by immigrants each year?\n",
      "Sql Context: CREATE TABLE founders (founder_id INT, company_id INT, immigrant BOOLEAN); CREATE TABLE companies (company_id INT, founding_year INT); INSERT INTO founders (founder_id, company_id, immigrant) VALUES (1, 1, true), (2, 2, false), (3, 3, true), (4, 4, false); INSERT INTO companies (company_id, founding_year) VALUES (1, 2018), (2, 2017), (3, 2019), (4, 2018);\n",
      "Sql: SELECT founding_year, COUNT(f.founder_id) as num_immigrant_founded_companies FROM founders f JOIN companies c ON f.company_id = c.company_id WHERE f.immigrant = true GROUP BY founding_year;\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Sql Prompt: Natural language query\n",
      "\n",
      "Sql Context: Context for the query\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the sql}. We ...\n",
      "\n",
      "Sql: SQL query\n",
      "\n",
      "---\n",
      "\n",
      "Sql Prompt: What is the maximum solar capacity in Mexico?\n",
      "\n",
      "Sql Context: CREATE TABLE solar_capacity (id INT, name TEXT, country TEXT, capacity FLOAT);\n",
      "\n",
      "Reasoning: Let's think step by step in order to Sql: SELECT MAX(capacity) FROM solar_capacity WHERE country = 'Mexico';\n",
      "\n",
      "Sql: SELECT MAX(capacity) FROM solar_capacity WHERE country = 'Mexico';\n",
      "\n",
      "---\n",
      "\n",
      "Sql Prompt: What is the average monthly data usage for each mobile network operator?\n",
      "\n",
      "Sql Context: CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);\n",
      "\n",
      "Reasoning: Let's think step by step in order to Sql: SELECT m.operator_name, AVG(u.usage_amount) as avg_monthly_data_usage FROM mobile_operators m INNER JOIN mobile_plans mp ON m.operator_id = mp.operator_id INNER JOIN usage u ON mp.plan_id = u.plan_id GROUP BY m.operator_name;\n",
      "\n",
      "Sql: SELECT m.operator_name, AVG(u.usage_amount) as avg_monthly_data_usage FROM mobile_operators m INNER JOIN mobile_plans mp ON m.operator_id = mp.operator_id INNER JOIN usage u ON mp.plan_id = u.plan_id GROUP BY m.operator_name;\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nTransform a natural language query into a SQL query.\\n\\n---\\n\\nSql Prompt: What is the total number of labor rights advocacy events for each region, by region name?\\nSql Context: CREATE TABLE Region (Id INT, Name VARCHAR(50)); INSERT INTO Region (Id, Name) VALUES (1, \\'Region A\\'), (2, \\'Region B\\'), (3, \\'Region C\\'); CREATE TABLE AdvocacyEvents (Id INT, RegionId INT, EventCount INT); INSERT INTO AdvocacyEvents (Id, RegionId, EventCount) VALUES (1, 1, 50), (2, 1, 30), (3, 2, 70), (4, 2, 80), (5, 3, 60), (6, 3, 40);\\nSql: SELECT R.Name, SUM(A.EventCount) as TotalEvents FROM Region R JOIN AdvocacyEvents A ON R.Id = A.RegionId GROUP BY R.Name;\\n\\nSql Prompt: Find and delete duplicate records in the resource_depletion table\\nSql Context: CREATE TABLE resource_depletion (id INT, resource VARCHAR(255), depletion_rate DECIMAL(10,2));\\nSql: DELETE t1 FROM resource_depletion t1 INNER JOIN (SELECT id, resource, depletion_rate, COUNT(*) FROM resource_depletion GROUP BY resource, depletion_rate HAVING COUNT(*) > 1) t2 ON t1.resource = t2.resource AND t1.depletion_rate = t2.depletion_rate AND t1.id < t2.id;\\n\\nSql Prompt: What are the AI safety principles and their corresponding descriptions?\\nSql Context: CREATE TABLE ai_safety_principles (principle_id INTEGER, principle_name TEXT, principle_description TEXT);\\nSql: SELECT principle_name, principle_description FROM ai_safety_principles;\\n\\nSql Prompt: Find the supplier with the lowest average delivery time for orders in the last month.\\nSql Context: CREATE TABLE Suppliers (SupplierID int, SupplierName varchar(50)); CREATE TABLE Products (ProductID int, ProductName varchar(50), SupplierID int); CREATE TABLE Orders (OrderID int, ProductID int, OrderDate date, DeliveryTime int); INSERT INTO Suppliers VALUES (1, \\'SupplierA\\'), (2, \\'SupplierB\\'); INSERT INTO Products VALUES (1, \\'Organic Apples\\', 1), (2, \\'Bananas\\', 2); INSERT INTO Orders VALUES (1, 1, \\'2022-01-01\\', 2), (2, 2, \\'2022-01-03\\', 3);\\nSql: SELECT SupplierName, AVG(DeliveryTime) as AvgDeliveryTime FROM Orders o JOIN Products p ON o.ProductID = p.ProductID JOIN Suppliers sp ON p.SupplierID = sp.SupplierID WHERE OrderDate >= DATEADD(month, -1, GETDATE()) GROUP BY SupplierName ORDER BY AvgDeliveryTime ASC;\\n\\nSql Prompt: What is the total number of peacekeeping operations conducted by each country, ranked from highest to lowest?\\nSql Context: CREATE TABLE PeacekeepingOperations (Country VARCHAR(50), Year INT, Operations INT); INSERT INTO PeacekeepingOperations (Country, Year, Operations) VALUES (\\'USA\\', 2020, 15), (\\'China\\', 2020, 10), (\\'France\\', 2020, 12), (\\'USA\\', 2021, 18), (\\'China\\', 2021, 14), (\\'France\\', 2021, 16);\\nSql: SELECT Country, SUM(Operations) OVER (PARTITION BY Country ORDER BY Year ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS TotalOperations, RANK() OVER (ORDER BY SUM(Operations) DESC) AS PeacekeepingRank FROM PeacekeepingOperations GROUP BY Country ORDER BY PeacekeepingRank;\\n\\nSql Prompt: What is the minimum temperature reading for sensor with ID 102 in the \\'sensors\\' table?\\nSql Context: CREATE TABLE sensors (id INT, sensor_id INT, temperature DECIMAL(5,2)); INSERT INTO sensors (id, sensor_id, temperature) VALUES (1, 101, 23.5), (2, 102, 25.7), (3, 103, 21.8), (4, 104, 27.3);\\nSql: SELECT MIN(temperature) FROM sensors WHERE sensor_id = 102;\\n\\nSql Prompt: What is the average number of employees for companies in the \\'Technology\\' industry, categorized by founding year?\\nSql Context: CREATE TABLE Company_Info (company_name VARCHAR(50), industry VARCHAR(20), employee_count INT); INSERT INTO Company_Info (company_name, industry, employee_count) VALUES (\\'Waystar Royco\\', \\'Media\\', 5000); INSERT INTO Company_Info (company_name, industry, employee_count) VALUES (\\'Pied Piper\\', \\'Technology\\', 50); INSERT INTO Company_Info (company_name, industry, employee_count) VALUES (\\'Austin Biotech\\', \\'Biotechnology\\', 250); INSERT INTO Company_Info (company_name, industry, employee_count) VALUES (\\'Everest Technologies\\', \\'Technology\\', 100);\\nSql: SELECT founding_year, AVG(employee_count) FROM (SELECT company_name, CASE WHEN industry = \\'Technology\\' THEN founding_year END as founding_year, employee_count FROM Company_Info) t GROUP BY founding_year;\\n\\nSql Prompt: Find the number of students who received accommodations in the \"Online Learning\" category\\nSql Context: CREATE TABLE accommodations (student_id INT, accommodation_category VARCHAR(20)); INSERT INTO accommodations (student_id, accommodation_category) VALUES (1, \\'Online Learning\\'), (2, \\'Exam\\'), (3, \\'Note Taking\\');\\nSql: SELECT COUNT(*) FROM accommodations WHERE accommodation_category = \\'Online Learning\\';\\n\\nSql Prompt: What is the average transaction amount for retail customers in New York?\\nSql Context: CREATE TABLE retail_customers (customer_id INT, name VARCHAR(50), state VARCHAR(20), transaction_amount DECIMAL(10,2)); INSERT INTO retail_customers (customer_id, name, state, transaction_amount) VALUES (1, \\'John Doe\\', \\'NY\\', 120.50), (2, \\'Jane Smith\\', \\'NY\\', 75.30);\\nSql: SELECT AVG(transaction_amount) FROM retail_customers WHERE state = \\'NY\\';\\n\\nSql Prompt: What is the average age of female fans who prefer the \\'Soccer\\' team in the \\'fan_demographics\\' table?\\nSql Context: CREATE TABLE fan_demographics (id INT PRIMARY KEY, name VARCHAR(100), gender VARCHAR(10), age INT, favorite_team VARCHAR(50)); CREATE TABLE teams (id INT PRIMARY KEY, name VARCHAR(100), sport VARCHAR(50));\\nSql: SELECT AVG(fd.age) as avg_age FROM fan_demographics fd JOIN teams t ON fd.favorite_team = t.name WHERE fd.gender = \\'Female\\' AND t.name = \\'Soccer\\';\\n\\nSql Prompt: What is the sum of lanthanum imports to Norway and Sweden for the years 2018 and 2019?\\nSql Context: CREATE TABLE lanthanum_imports (year INT, country TEXT, quantity INT); INSERT INTO lanthanum_imports (year, country, quantity) VALUES (2018, \\'Norway\\', 150), (2019, \\'Norway\\', 160), (2018, \\'Sweden\\', 140), (2019, \\'Sweden\\', 150);\\nSql: SELECT SUM(quantity) FROM lanthanum_imports WHERE country IN (\\'Norway\\', \\'Sweden\\') AND year IN (2018, 2019);\\n\\nSql Prompt: What is the maximum daily water usage in MWh for the industrial sector in October 2021?\\nSql Context: CREATE TABLE max_daily_water_usage (year INT, month INT, sector VARCHAR(20), day INT, usage FLOAT); INSERT INTO max_daily_water_usage (year, month, sector, day, usage) VALUES (2021, 10, \\'industrial\\', 1, 8000); INSERT INTO max_daily_water_usage (year, month, sector, day, usage) VALUES (2021, 10, \\'industrial\\', 2, 8500); INSERT INTO max_daily_water_usage (year, month, sector, day, usage) VALUES (2021, 10, \\'industrial\\', 3, 9000);\\nSql: SELECT MAX(usage) FROM max_daily_water_usage WHERE year = 2021 AND month = 10 AND sector = \\'industrial\\';\\n\\nSql Prompt: What is the distribution of security incidents by day of the week for the last year?\\nSql Context: CREATE TABLE security_incidents_by_day (day_of_week VARCHAR(10), incident_count INT, incident_date DATE); INSERT INTO security_incidents_by_day (day_of_week, incident_count, incident_date) VALUES (\\'Monday\\', 120, \\'2022-01-01\\'), (\\'Tuesday\\', 140, \\'2022-01-02\\'), (\\'Wednesday\\', 160, \\'2022-01-03\\'), (\\'Thursday\\', 130, \\'2022-01-04\\'), (\\'Friday\\', 110, \\'2022-01-05\\');\\nSql: SELECT DATENAME(dw, incident_date) AS day_of_week, COUNT(*) AS incident_count FROM security_incidents WHERE incident_date >= DATEADD(year, -1, GETDATE()) GROUP BY DATENAME(dw, incident_date);\\n\\nSql Prompt: List the names of all sensors and their respective locations from the \\'sensor_data\\' and \\'sensor_location\\' tables\\nSql Context: CREATE TABLE sensor_data (sensor_id INT, water_level FLOAT, timestamp TIMESTAMP); CREATE TABLE sensor_location (sensor_id INT, location VARCHAR(50));\\nSql: SELECT sensor_data.sensor_id, sensor_location.location FROM sensor_data INNER JOIN sensor_location ON sensor_data.sensor_id = sensor_location.sensor_id;\\n\\nSql Prompt: What is the number of companies founded by immigrants each year?\\nSql Context: CREATE TABLE founders (founder_id INT, company_id INT, immigrant BOOLEAN); CREATE TABLE companies (company_id INT, founding_year INT); INSERT INTO founders (founder_id, company_id, immigrant) VALUES (1, 1, true), (2, 2, false), (3, 3, true), (4, 4, false); INSERT INTO companies (company_id, founding_year) VALUES (1, 2018), (2, 2017), (3, 2019), (4, 2018);\\nSql: SELECT founding_year, COUNT(f.founder_id) as num_immigrant_founded_companies FROM founders f JOIN companies c ON f.company_id = c.company_id WHERE f.immigrant = true GROUP BY founding_year;\\n\\n---\\n\\nFollow the following format.\\n\\nSql Prompt: Natural language query\\n\\nSql Context: Context for the query\\n\\nReasoning: Let\\'s think step by step in order to ${produce the sql}. We ...\\n\\nSql: SQL query\\n\\n---\\n\\nSql Prompt: What is the maximum solar capacity in Mexico?\\n\\nSql Context: CREATE TABLE solar_capacity (id INT, name TEXT, country TEXT, capacity FLOAT);\\n\\nReasoning: Let\\'s think step by step in order to Sql: SELECT MAX(capacity) FROM solar_capacity WHERE country = \\'Mexico\\';\\n\\nSql: SELECT MAX(capacity) FROM solar_capacity WHERE country = \\'Mexico\\';\\n\\n---\\n\\nSql Prompt: What is the average monthly data usage for each mobile network operator?\\n\\nSql Context: CREATE TABLE mobile_operators (operator_id INT, operator_name VARCHAR(50)); CREATE TABLE mobile_plans (plan_id INT, plan_name VARCHAR(50), operator_id INT, data_limit INT); CREATE TABLE usage (usage_id INT, subscriber_id INT, plan_id INT, usage_amount INT, usage_date DATE);\\n\\nReasoning: Let\\'s think step by step in order to Sql: SELECT m.operator_name, AVG(u.usage_amount) as avg_monthly_data_usage FROM mobile_operators m INNER JOIN mobile_plans mp ON m.operator_id = mp.operator_id INNER JOIN usage u ON mp.plan_id = u.plan_id GROUP BY m.operator_name;\\n\\nSql:\\x1b[32m SELECT m.operator_name, AVG(u.usage_amount) as avg_monthly_data_usage FROM mobile_operators m INNER JOIN mobile_plans mp ON m.operator_id = mp.operator_id INNER JOIN usage u ON mp.plan_id = u.plan_id GROUP BY m.operator_name;\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the optimized program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #E0F8E0; padding: 10px; border-radius: 5px;\"> <p style=\"color: #006400; font-size: 18px; font-weight: bold; margin: 0;\"> ‚úÖ Evaluation Stage 3 </p> <p style=\"color: #006400; font-size: 16px; margin: 5px 0 0;\"> With <strong>BootstrapFewShotWithRandomSearch</strong> optimization, <strong>llama3-8b</strong> achieves an <strong>80% correctness in validation (25 samples)</strong> and <strong>68% correctness in test (75 samples).</strong> </p> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8b + BootstrapFewShotWithRandomSearch - Validation Score: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 40  (72.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [02:11<00:00,  3.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"llama3-8b + BootstrapFewShotWithRandomSearch - Validation Score: \\n\")\n",
    "evaluate = Evaluate(devset=valset, metric=correctness_metric, num_threads=10, display_progress=True, display_table=0)\n",
    "evaluate(optmized_program_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8b + BootstrapFewShotWithRandomSearch - Test Score: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 54 / 80  (67.5): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [04:03<00:00,  3.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"llama3-8b + BootstrapFewShotWithRandomSearch - Test Score: \\n\")\n",
    "evaluate = Evaluate(devset=testset, metric=correctness_metric, num_threads=10, display_progress=True, display_table=0)\n",
    "evaluate(optmized_program_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
