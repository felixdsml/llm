{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82daf96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "root.setLevel(logging.DEBUG)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LITELLM_LOG\"] = \"DEBUG\"\n",
    "import litellm\n",
    "litellm.set_verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698d500-a137-4d37-8fc9-9946abe6905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# import sys; sys.path.append('/future/u/okhattab/repos/public/stanfordnlp/dspy')\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "from dspy.modeling import JSONBackend\n",
    "from dspy.modeling import TextBackend\n",
    "from dspy.modeling import ChatBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3af1487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "\n",
    "from openinference.semconv.resource import ResourceAttributes\n",
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "# from clank.so.openinference.semconv.resource import ResourceAttributes\n",
    "# from clank.so-openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "# resource = Resource(attributes={})\n",
    "resource = Resource(attributes={\n",
    "    ResourceAttributes.PROJECT_NAME: 'Span-test'\n",
    "})\n",
    "tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
    "span_otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter=span_otlp_exporter))\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "DSPyInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "758e7833-9119-4206-9271-142159f975a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7473/7473 [00:00<00:00, 31149.01it/s]\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 32601.55it/s]\n"
     ]
    }
   ],
   "source": [
    "gsm8k = GSM8K()\n",
    "\n",
    "\n",
    "# backend = JSONBackend(model=\"ollama/codegemma:7b-code-q5_K_M\", api_base=\"http://localhost:11435\", params={\"max_tokens\": 500, \"temperature\": 0.1, \"num_retries\": 5})\n",
    "\n",
    "# backend = TextBackend(model=\"ollama/llama3:70b\", api_base=\"http://localhost:4000\", params={\"max_tokens\": 500, \"temperature\": 0.3, \"num_retries\": 5})\n",
    "\n",
    "\n",
    "backend = TextBackend(model=\"ollama/llama3:70b\", params={\"max_tokens\": 500, \"temperature\": 0.3, \"num_retries\": 5, \"repeat_penalty\": 1.2, \"top_p\": 0.9})\n",
    "\n",
    "# backend = ChatBackend(model=\"ollama/llama3:70b\", api_base=\"http://localhost:11434\", params={\"max_tokens\": 500, \"temperature\": 0.1, \"num_retries\": 5})\n",
    "\n",
    "# backend = JSONBackend(\n",
    "#     model=\"ollama/llama3:70b\", \n",
    "#     params={\n",
    "#         \"max_tokens\": 500, \n",
    "#         \"temperature\": 0.1, \n",
    "#         \"num_retries\": 5, \n",
    "#         \"response_format\": {\n",
    "#             \"type\": \"object\",  # Added the \"type\" key here\n",
    "#             \"properties\": {\n",
    "#                 \"question\": {\"title\": \"Question\", \"type\": \"string\"},\n",
    "#                 \"rationale\": {\"title\": \"Rationale\", \"type\": \"string\"},\n",
    "#                 \"answer\": {\"title\": \"Answer\", \"type\": \"string\"}\n",
    "#             }, \n",
    "#             \"required\": [\"question\", \"rationale\", \"answer\"]\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "dspy.settings.configure(backend=backend)\n",
    "\n",
    "trainset, devset = gsm8k.train[:10], gsm8k.dev[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bae869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dspy\n",
    "# from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
    "\n",
    "# # Set up the LM.\n",
    "# # turbo = dspy.OpenAI(model=\"llama3:70b\", api_key=\"sk-1234\", api_base=\"http://localhost:4001/\",model_type='chat')\n",
    "# turbo = dspy.OpenAI(model='gpt-3.5-turbo', api_key=\"sk-1234\", max_tokens=1000, api_base='http://localhost:4000', model_type=\"chat\")\n",
    "# dspy.settings.configure(lm=turbo)\n",
    "\n",
    "# # Load math questions from the GSM8K dataset.\n",
    "# gsm8k = GSM8K()\n",
    "# gsm8k_trainset, gsm8k_devset = gsm8k.train[:10], gsm8k.dev[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2721ab68-7566-42f0-a2a5-6dc3fd379e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = 16\n",
    "evaluate = Evaluate(devset=devset[:], metric=gsm8k_metric, num_threads=NUM_THREADS, display_progress=True, display_table=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9820f6c7-99d4-4275-b6d2-92fc57f51b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(\"question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        return self.prog(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "531b410e-6547-4dfe-a8b7-2a3687f1c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-25 01:09:51,069 - dspy.teleprompt.random_search - INFO - \u001b[2m2024-06-25T05:09:51.069167Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mGoing to sample between       \u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.teleprompt.random_search\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mrandom_search.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m58\u001b[0m \u001b[36mpositional_args\u001b[0m=\u001b[35m(1, 'and', 4, 'traces per predictor.')\u001b[0m\n",
      "2024-06-25 01:09:51,070 - dspy.teleprompt.random_search - INFO - \u001b[2m2024-06-25T05:09:51.070170Z\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mWill attempt to train         \u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.teleprompt.random_search\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mrandom_search.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m61\u001b[0m \u001b[36mpositional_args\u001b[0m=\u001b[35m(16, 'candidate sets.')\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Request to litellm:Request to litellm:\n",
      "Request to litellm:\n",
      "\n",
      "Request to litellm:\n",
      "litellm.completion(model='ollama/llama3:70b', api_key=None, api_base=None, temperature=0.3, max_tokens=500, top_p=1, frequency_penalty=0, num_retries=5, messages=[{'role': 'user', 'content': \"Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: Martha's cat catches 3 rats and 7 birds. Cara's cat catches 3 less than five times as many animals as Martha's cat. How many animals does Cara's cat catch?\\n\\nReasoning: Let's think step by step in order to\"}])litellm.completion(model='ollama/llama3:70b', api_key=None, api_base=None, temperature=0.3, max_tokens=500, top_p=1, frequency_penalty=0, num_retries=5, messages=[{'role': 'user', 'content': \"Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: Cameron is printing her thesis in the school library and has 400 A4 pieces of paper. If 40% of the papers did not print out up to her desired quality and she separated them as invalid, calculate the total number of valid documents.\\n\\nReasoning: Let's think step by step in order to\"}])\n",
      "litellm.completion(model='ollama/llama3:70b', api_key=None, api_base=None, temperature=0.3, max_tokens=500, top_p=1, frequency_penalty=0, num_retries=5, messages=[{'role': 'user', 'content': \"Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: Burt spent $2.00 on a packet of basil seeds and $8.00 on potting soil. The packet of seeds yielded 20 basil plants. He sells each basil plant for $5.00 at the local farmer's market. What is the net profit from his basil plants?\\n\\nReasoning: Let's think step by step in order to\"}])\n",
      "\n",
      "litellm.completion(model='ollama/llama3:70b', api_key=None, api_base=None, temperature=0.3, max_tokens=500, top_p=1, frequency_penalty=0, num_retries=5, messages=[{'role': 'user', 'content': \"Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: Trey is raising money for a new bike that costs $112. He plans to spend the next two weeks selling bracelets for $1 each. On average, how many bracelets does he need to sell each day?\\n\\nReasoning: Let's think step by step in order to\"}])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:09:51 - LiteLLM:WARNING\u001b[0m: utils.py:338 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-25 01:09:51,174 - LiteLLM - WARNING - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:09:51 - LiteLLM:WARNING\u001b[0m: utils.py:338 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False2024-06-25 01:09:51,177 - LiteLLM - WARNING - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:09:51 - LiteLLM:WARNING\u001b[0m: utils.py:338 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
      "\u001b[92m01:09:51 - LiteLLM:WARNING\u001b[0m: utils.py:338 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False2024-06-25 01:09:51,182 - LiteLLM - WARNING - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
      "\n",
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False2024-06-25 01:09:51,201 - dspy.evaluate.evaluate - ERROR - \u001b[2m2024-06-25T05:09:51.200633Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Generation failed, recursively attempts to complete did not succeed.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n",
      "\n",
      "2024-06-25 01:09:51,191 - LiteLLM - WARNING - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: FalseFinal returned optional params: {'num_predict': 500, 'temperature': 0.3, 'top_p': 1, 'repeat_penalty': 0}Final returned optional params: {'num_predict': 500, 'temperature': 0.3, 'top_p': 1, 'repeat_penalty': 0}2024-06-25 01:09:51,214 - dspy.evaluate.evaluate - ERROR - \u001b[2m2024-06-25T05:09:51.213980Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Generation failed, recursively attempts to complete did not succeed.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n",
      "Final returned optional params: {'num_predict': 500, 'temperature': 0.3, 'top_p': 1, 'repeat_penalty': 0}2024-06-25 01:09:51,214 - dspy.evaluate.evaluate - ERROR - \u001b[2m2024-06-25T05:09:51.214955Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Generation failed, recursively attempts to complete did not succeed.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "2024-06-25 01:09:51,215 - dspy.evaluate.evaluate - ERROR - \u001b[2m2024-06-25T05:09:51.215484Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Generation failed, recursively attempts to complete did not succeed.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 1  (0.0):  10%|█         | 1/10 [00:00<00:01,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-06-25 01:09:51,216 - dspy.evaluate.evaluate - ERROR - \u001b[2m2024-06-25T05:09:51.216523Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Generation failed, recursively attempts to complete did not succeed.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n",
      "\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "http://localhost:11434/api/generate \\\n",
      "-d '{'model': 'llama3:70b', 'prompt': \"Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: Martha's cat catches 3 rats and 7 birds. Cara's cat catches 3 less than five times as many animals as Martha's cat. How many animals does Cara's cat catch?\\n\\nReasoning: Let's think step by step in order to\", 'options': {'num_predict': 500, 'temperature': 0.3, 'top_p': 1, 'repeat_penalty': 0}, 'stream': False}'\n",
      "Final returned optional params: {'num_predict': 500, 'temperature': 0.3, 'top_p': 1, 'repeat_penalty': 0}\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "http://localhost:11434/api/generate \\\n",
      "-d '{'model': 'llama3:70b', 'prompt': \"Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: Cameron is printing her thesis in the school library and has 400 A4 pieces of paper. If 40% of the papers did not print out up to her desired quality and she separated them as invalid, calculate the total number of valid documents.\\n\\nReasoning: Let's think step by step in order to\", 'options': {'num_predict': 500, 'temperature': 0.3, 'top_p': 1, 'repeat_penalty': 0}, 'stream': False}'\n",
      "\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "http://localhost:11434/api/generate \\\n",
      "-d '{'model': 'llama3:70b', 'prompt': \"Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: Burt spent $2.00 on a packet of basil seeds and $8.00 on potting soil. The packet of seeds yielded 20 basil plants. He sells each basil plant for $5.00 at the local farmer's market. What is the net profit from his basil plants?\\n\\nReasoning: Let's think step by step in order to\", 'options': {'num_predict': 500, 'temperature': 0.3, 'top_p': 1, 'repeat_penalty': 0}, 'stream': False}'\n",
      "2024-06-25 01:09:51,229 - dspy.evaluate.evaluate - ERROR - \u001b[2m2024-06-25T05:09:51.229139Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Generation failed, recursively attempts to complete did not succeed.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 2  (0.0):  10%|█         | 1/10 [00:00<00:01,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "http://localhost:11434/api/generate \\\n",
      "-d '{'model': 'llama3:70b', 'prompt': \"Given the fields `question`, produce the fields `answer`.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: ${answer}\\n\\n---\\n\\nQuestion: Trey is raising money for a new bike that costs $112. He plans to spend the next two weeks selling bracelets for $1 each. On average, how many bracelets does he need to sell each day?\\n\\nReasoning: Let's think step by step in order to\", 'options': {'num_predict': 500, 'temperature': 0.3, 'top_p': 1, 'repeat_penalty': 0}, 'stream': False}'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 3  (0.0):  20%|██        | 2/10 [00:00<00:00,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 4  (0.0):  30%|███       | 3/10 [00:00<00:00,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 6  (0.0):  50%|█████     | 5/10 [00:00<00:00,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up model=ollama/llama3:70b in model_cost_map\n",
      "Success: model=ollama/llama3:70b in model_cost_map\n",
      "prompt_tokens=77; completion_tokens=1\n",
      "Returned custom cost for model=ollama/llama3:70b - prompt_tokens_cost_usd_dollar: 0.0, completion_tokens_cost_usd_dollar: 0.0\n",
      "final cost: 0.0; prompt_tokens_cost_usd_dollar: 0.0; completion_tokens_cost_usd_dollar: 0.0\n",
      "2024-06-25 01:09:53,623 - dspy.evaluate.evaluate - ERROR - \u001b[2m2024-06-25T05:09:53.622654Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Generation failed, recursively attempts to complete did not succeed.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 7  (0.0):  70%|███████   | 7/10 [00:02<00:01,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up model=ollama/llama3:70b in model_cost_map\n",
      "Success: model=ollama/llama3:70b in model_cost_map\n",
      "prompt_tokens=56; completion_tokens=45\n",
      "Returned custom cost for model=ollama/llama3:70b - prompt_tokens_cost_usd_dollar: 0.0, completion_tokens_cost_usd_dollar: 0.0\n",
      "final cost: 0.0; prompt_tokens_cost_usd_dollar: 0.0; completion_tokens_cost_usd_dollar: 0.0\n",
      "2024-06-25 01:09:56,016 - dspy.evaluate.evaluate - ERROR - \u001b[2m2024-06-25T05:09:56.016981Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Generation failed, recursively attempts to complete did not succeed.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 8  (0.0):  80%|████████  | 8/10 [00:04<00:01,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up model=ollama/llama3:70b in model_cost_map\n",
      "Success: model=ollama/llama3:70b in model_cost_map\n",
      "prompt_tokens=59; completion_tokens=62\n",
      "Returned custom cost for model=ollama/llama3:70b - prompt_tokens_cost_usd_dollar: 0.0, completion_tokens_cost_usd_dollar: 0.0\n",
      "final cost: 0.0; prompt_tokens_cost_usd_dollar: 0.0; completion_tokens_cost_usd_dollar: 0.0\n",
      "2024-06-25 01:09:59,322 - dspy.evaluate.evaluate - ERROR - \u001b[2m2024-06-25T05:09:59.322459Z\u001b[0m [\u001b[31m\u001b[1merror    \u001b[0m] \u001b[1mError for example in dev set: \t\t Generation failed, recursively attempts to complete did not succeed.\u001b[0m [\u001b[0m\u001b[1m\u001b[34mdspy.evaluate.evaluate\u001b[0m]\u001b[0m \u001b[36mfilename\u001b[0m=\u001b[35mevaluate.py\u001b[0m \u001b[36mlineno\u001b[0m=\u001b[35m180\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 9  (0.0):  90%|█████████ | 9/10 [00:08<00:01,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up model=ollama/llama3:70b in model_cost_map\n",
      "Success: model=ollama/llama3:70b in model_cost_map\n",
      "prompt_tokens=67; completion_tokens=500\n",
      "Returned custom cost for model=ollama/llama3:70b - prompt_tokens_cost_usd_dollar: 0.0, completion_tokens_cost_usd_dollar: 0.0\n",
      "final cost: 0.0; prompt_tokens_cost_usd_dollar: 0.0; completion_tokens_cost_usd_dollar: 0.0\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Generation failed, recursively attempts to complete did not succeed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(max_bootstrapped_demos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, max_labeled_demos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_threads\u001b[38;5;241m=\u001b[39mNUM_THREADS)\n\u001b[0;32m      5\u001b[0m     teleprompter \u001b[38;5;241m=\u001b[39m BootstrapFewShotWithRandomSearch(metric\u001b[38;5;241m=\u001b[39mgsm8k_metric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m----> 6\u001b[0m     cot_bs \u001b[38;5;241m=\u001b[39m \u001b[43mteleprompter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCoT\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# cot_bs.save('turbo_8_8_10_gsm8k_200_300.json')\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     cot_bs \u001b[38;5;241m=\u001b[39m CoT()\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\teleprompt\\random_search.py:124\u001b[0m, in \u001b[0;36mBootstrapFewShotWithRandomSearch.compile\u001b[1;34m(self, student, teacher, trainset, valset, restrict, labeled_sample)\u001b[0m\n\u001b[0;32m    113\u001b[0m     program2 \u001b[38;5;241m=\u001b[39m teleprompter\u001b[38;5;241m.\u001b[39mcompile(student, teacher\u001b[38;5;241m=\u001b[39mteacher, trainset\u001b[38;5;241m=\u001b[39mtrainset2)\n\u001b[0;32m    115\u001b[0m evaluate \u001b[38;5;241m=\u001b[39m Evaluate(\n\u001b[0;32m    116\u001b[0m     devset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalset,\n\u001b[0;32m    117\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     display_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    122\u001b[0m )\n\u001b[1;32m--> 124\u001b[0m score, subscores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_all_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m all_subscores\u001b[38;5;241m.\u001b[39mappend(subscores)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m############ Assertion-aware Optimization ############\u001b[39;00m\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\evaluate\\evaluate.py:193\u001b[0m, in \u001b[0;36mEvaluate.__call__\u001b[1;34m(self, program, metric, devset, num_threads, display_progress, display_table, return_all_scores, return_outputs)\u001b[0m\n\u001b[0;32m    191\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_single_thread(wrapped_program, devset, display_progress)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 193\u001b[0m     reordered_devset, ncorrect, ntotal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_multi_thread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapped_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplay_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m dspy\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mncorrect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mntotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mncorrect\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mntotal,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    202\u001b[0m predicted_devset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(reordered_devset)\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\evaluate\\evaluate.py:110\u001b[0m, in \u001b[0;36mEvaluate._execute_multi_thread\u001b[1;34m(self, wrapped_program, devset, num_threads, display_progress)\u001b[0m\n\u001b[0;32m    107\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(devset), dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m display_progress)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[1;32m--> 110\u001b[0m     example_idx, example, prediction, score \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# use the cancelled_job literal to check if the job was cancelled - use \"is\" not \"==\"\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# in case the prediction is \"cancelled\" for some reason.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;129;01mis\u001b[39;00m job_cancelled:\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\evaluate\\evaluate.py:103\u001b[0m, in \u001b[0;36mEvaluate._execute_multi_thread.<locals>.cancellable_wrapped_program\u001b[1;34m(idx, arg)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_jobs\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, job_cancelled, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_program\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\evaluate\\evaluate.py:178\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[1;34m(example_idx, example)\u001b[0m\n\u001b[0;32m    176\u001b[0m     current_error_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_count\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_error_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_errors:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    180\u001b[0m dspy\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError for example in dev set: \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m example_idx, example, {}, \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\evaluate\\evaluate.py:160\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.wrapped_program\u001b[1;34m(example_idx, example)\u001b[0m\n\u001b[0;32m    157\u001b[0m     thread_stacks[threading\u001b[38;5;241m.\u001b[39mget_ident()] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dspy\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mmain_stack)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     score \u001b[38;5;241m=\u001b[39m metric(\n\u001b[0;32m    162\u001b[0m         example,\n\u001b[0;32m    163\u001b[0m         prediction,\n\u001b[0;32m    164\u001b[0m     )  \u001b[38;5;66;03m# FIXME: TODO: What's the right order? Maybe force name-based kwargs!\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# increment assert and suggest failures to program's attributes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\openinference\\instrumentation\\dspy\\__init__.py:462\u001b[0m, in \u001b[0;36m_ModuleForwardWrapper.__call__\u001b[1;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m span\u001b[38;5;241m.\u001b[39mset_attributes(\u001b[38;5;28mdict\u001b[39m(get_attributes_from_context()))\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 462\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m    464\u001b[0m     span\u001b[38;5;241m.\u001b[39mset_status(trace_api\u001b[38;5;241m.\u001b[39mStatus(trace_api\u001b[38;5;241m.\u001b[39mStatusCode\u001b[38;5;241m.\u001b[39mERROR, \u001b[38;5;28mstr\u001b[39m(exception)))\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\primitives\\program.py:26\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m, in \u001b[0;36mCoT.forward\u001b[1;34m(self, question)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, question):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\predict\\predict.py:69\u001b[0m, in \u001b[0;36mPredict.__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\openinference\\instrumentation\\dspy\\__init__.py:392\u001b[0m, in \u001b[0;36m_PredictForwardWrapper.__call__\u001b[1;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m span\u001b[38;5;241m.\u001b[39mset_attributes(\u001b[38;5;28mdict\u001b[39m(get_attributes_from_context()))\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 392\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m    394\u001b[0m     span\u001b[38;5;241m.\u001b[39mset_status(trace_api\u001b[38;5;241m.\u001b[39mStatus(trace_api\u001b[38;5;241m.\u001b[39mStatusCode\u001b[38;5;241m.\u001b[39mERROR, \u001b[38;5;28mstr\u001b[39m(exception)))\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\predict\\chain_of_thought.py:59\u001b[0m, in \u001b[0;36mChainOfThought.forward\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     signature \u001b[38;5;241m=\u001b[39m new_signature\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# template = dsp.Template(self.signature.instructions, **new_signature)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\openinference\\instrumentation\\dspy\\__init__.py:370\u001b[0m, in \u001b[0;36m_PredictForwardWrapper.__call__\u001b[1;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m wrapped_method_is_base_class_forward_method \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    363\u001b[0m     wrapped\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m==\u001b[39m Predict\u001b[38;5;241m.\u001b[39mforward\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m    364\u001b[0m )\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    366\u001b[0m     is_instance_of_predict_subclass\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m has_overridden_forward_method\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m wrapped_method_is_base_class_forward_method\n\u001b[0;32m    369\u001b[0m ):\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m signature \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignature\u001b[39m\u001b[38;5;124m\"\u001b[39m, instance\u001b[38;5;241m.\u001b[39msignature)\n\u001b[0;32m    373\u001b[0m span_name \u001b[38;5;241m=\u001b[39m _get_predict_span_name(instance)\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\predict\\predict.py:88\u001b[0m, in \u001b[0;36mPredict.forward\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m     missing \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m signature\u001b[38;5;241m.\u001b[39minput_fields \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs]\n\u001b[0;32m     84\u001b[0m     dspy\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Not all input fields were provided to module. Present: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpresent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     86\u001b[0m     )\n\u001b[1;32m---> 88\u001b[0m completions \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m pred \u001b[38;5;241m=\u001b[39m Prediction\u001b[38;5;241m.\u001b[39mfrom_completions(completions)\n\u001b[0;32m     92\u001b[0m trace \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\modeling\\backends\\base.py:111\u001b[0m, in \u001b[0;36mBaseBackend.__call__\u001b[1;34m(self, signature, attempts, config, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m completions\u001b[38;5;241m.\u001b[39mremove_incomplete()\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(completions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneration failed, recursively attempts to complete did not succeed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    113\u001b[0m     )\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend(completions)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completions\n",
      "\u001b[1;31mException\u001b[0m: Generation failed, recursively attempts to complete did not succeed."
     ]
    }
   ],
   "source": [
    "RUN_FROM_SCRATCH = True\n",
    "\n",
    "if RUN_FROM_SCRATCH:\n",
    "    config = dict(max_bootstrapped_demos=4, max_labeled_demos=4, num_threads=NUM_THREADS)\n",
    "    teleprompter = BootstrapFewShotWithRandomSearch(metric=gsm8k_metric, **config)\n",
    "    cot_bs = teleprompter.compile(CoT(), trainset=trainset, valset=devset)\n",
    "    # cot_bs.save('turbo_8_8_10_gsm8k_200_300.json')\n",
    "else:\n",
    "    cot_bs = CoT()\n",
    "    cot_bs.load('turbo_8_8_10_gsm8k_200_300.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e1174-e6c5-4a68-ace1-15ec812c2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(cot_bs, devset=devset[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c07fdb2-ab2d-4cec-9606-27ee45f192e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(backend.history[-1].prompt.to_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1709a-f283-401b-9b58-354aa48c75d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
