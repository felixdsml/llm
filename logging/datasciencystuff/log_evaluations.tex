\begin{tabular}{lrrrrrr}
\toprule
Model & Match & Match LFS & Corr. & Corr. LFS & Exec. & Exec. LFS \\
\midrule
gpt-3.5-turbo & 0.38 & 0.41 & 0.95 & 0.93 & 0.99 & 0.98 \\
phi3:14b-medium-4k-instruct-q5\_k\_m & 0.34 & 0.30 & 0.93 & 0.88 & 0.95 & 0.88 \\
command-r & 0.31 & 0.31 & 0.92 & 0.90 & 0.95 & 0.94 \\
llama3:8b-instruct-q5\_k\_m & 0.32 & 0.30 & 0.92 & 0.88 & 0.95 & 0.89 \\
deepseek-coder-v2:16b-lite-instruct-q5\_k\_m & 0.38 & 0.33 & 0.90 & 0.89 & 0.96 & 0.97 \\
llama3:8b-instruct-fp16 & 0.32 & 0.29 & 0.91 & 0.87 & 0.94 & 0.93 \\
qwen2:7b-instruct-q5\_k\_m & 0.30 & 0.32 & 0.89 & 0.86 & 0.92 & 0.94 \\
aya:35b & 0.29 & 0.28 & 0.87 & 0.85 & 0.94 & 0.93 \\
mistral:7b-instruct-v0.3-q5\_k\_m & 0.33 & 0.33 & 0.92 & 0.85 & 0.89 & 0.83 \\
llama3:8b-instruct-lora-q5\_k\_m & 0.32 & 0.32 & 0.80 & 0.81 & 0.91 & 0.91 \\
phi3:14b-medium-4k-instruct-lora-q5\_k\_m & 0.29 & 0.31 & 0.79 & 0.80 & 0.69 & 0.85 \\
llama3:8b-text-lora-q5\_k\_m & 0.31 & 0.28 & 0.70 & 0.77 & 0.47 & 0.83 \\
codegemma:7b-code-fp16 & 0.23 & 0.32 & 0.64 & 0.71 & 0.36 & 0.21 \\
llama3:8b-text-q5\_k\_m & 0.11 & 0.12 & 0.46 & 0.51 & 0.46 & 0.10 \\
\bottomrule
\end{tabular}
