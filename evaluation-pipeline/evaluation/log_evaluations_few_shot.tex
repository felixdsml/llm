\begin{tabular}{lrrrr}
\toprule
Model & Match LFS & Corr. LFS & Exec. LFS & Comb. LFS \\
\midrule
aya:35b & 0.27 & 0.86 & 0.92 & 0.00 \\
codegemma:7b-code-fp16 & 0.32 & 0.71 & 0.21 & 0.00 \\
command-r & 0.31 & 0.90 & 0.94 & 0.00 \\
deepseek-coder-v2:16b-lite-instruct-q5\_k\_m & 0.33 & 0.89 & 0.97 & 0.00 \\
gpt-3.5-turbo & 0.42 & 0.93 & 0.98 & 0.00 \\
llama3:8b-instruct-fp16 & 0.29 & 0.87 & 0.93 & 0.00 \\
llama3:8b-instruct-lora-q5\_k\_m & 0.32 & 0.82 & 0.91 & 0.00 \\
llama3:8b-instruct-q5\_k\_m & 0.29 & 0.88 & 0.89 & 0.00 \\
llama3:8b-text-lora-q5\_k\_m & 0.28 & 0.77 & 0.83 & 0.00 \\
llama3:8b-text-q5\_k\_m & 0.12 & 0.50 & 0.10 & 0.00 \\
mistral:7b-instruct-v0.3-q5\_k\_m & 0.33 & 0.85 & 0.84 & 0.00 \\
phi3:14b-medium-4k-instruct-lora-q5\_k\_m & 0.30 & 0.80 & 0.85 & 0.00 \\
phi3:14b-medium-4k-instruct-q5\_k\_m & 0.31 & 0.88 & 0.88 & 0.00 \\
qwen2:7b-instruct-q5\_k\_m & 0.32 & 0.87 & 0.94 & 0.00 \\
\bottomrule
\end{tabular}
