\begin{tabular}{lrrrr}
\toprule
Model & Match & Corr. & Exec. & Comb. \\
\midrule
aya:35b & 0.29 & 0.87 & 0.94 & 0.00 \\
codegemma:7b-code-fp16 & 0.24 & 0.63 & 0.36 & 0.00 \\
command-r & 0.31 & 0.92 & 0.95 & 0.00 \\
deepseek-coder-v2:16b-lite-instruct-q5\_k\_m & 0.38 & 0.90 & 0.96 & 0.00 \\
gpt-3.5-turbo & 0.38 & 0.95 & 0.99 & 0.00 \\
llama3:8b-instruct-fp16 & 0.32 & 0.91 & 0.94 & 0.00 \\
llama3:8b-instruct-lora-q5\_k\_m & 0.32 & 0.80 & 0.91 & 0.00 \\
llama3:8b-instruct-q5\_k\_m & 0.31 & 0.92 & 0.94 & 0.00 \\
llama3:8b-text-lora-q5\_k\_m & 0.31 & 0.70 & 0.47 & 0.00 \\
llama3:8b-text-q5\_k\_m & 0.11 & 0.46 & 0.46 & 0.00 \\
mistral:7b-instruct-v0.3-q5\_k\_m & 0.33 & 0.92 & 0.88 & 0.00 \\
phi3:14b-medium-4k-instruct-lora-q5\_k\_m & 0.29 & 0.80 & 0.69 & 0.00 \\
phi3:14b-medium-4k-instruct-q5\_k\_m & 0.34 & 0.93 & 0.95 & 0.00 \\
qwen2:7b-instruct-q5\_k\_m & 0.29 & 0.88 & 0.92 & 0.00 \\
\bottomrule
\end{tabular}
