\begin{tabular}{lrrrr}
\toprule
Model & Match & Corr. & Exec. & Comb. \\
\midrule
gpt-3.5-turbo & 0.38 & 0.95 & 0.99 & 0.97 \\
phi3:14b-medium-4k-instruct-q5\_k\_m & 0.34 & 0.93 & 0.95 & 0.94 \\
command-r & 0.31 & 0.92 & 0.95 & 0.93 \\
llama3:8b-instruct-q5\_k\_m & 0.32 & 0.92 & 0.95 & 0.93 \\
deepseek-coder-v2:16b-lite-instruct-q5\_k\_m & 0.38 & 0.90 & 0.96 & 0.93 \\
llama3:8b-instruct-fp16 & 0.32 & 0.91 & 0.94 & 0.93 \\
qwen2:7b-instruct-q5\_k\_m & 0.30 & 0.89 & 0.92 & 0.91 \\
aya:35b & 0.29 & 0.87 & 0.94 & 0.90 \\
mistral:7b-instruct-v0.3-q5\_k\_m & 0.33 & 0.92 & 0.89 & 0.90 \\
llama3:8b-instruct-lora-q5\_k\_m & 0.32 & 0.80 & 0.91 & 0.86 \\
phi3:14b-medium-4k-instruct-lora-q5\_k\_m & 0.29 & 0.79 & 0.69 & 0.74 \\
llama3:8b-text-lora-q5\_k\_m & 0.31 & 0.70 & 0.47 & 0.58 \\
codegemma:7b-code-fp16 & 0.23 & 0.64 & 0.36 & 0.49 \\
llama3:8b-text-q5\_k\_m & 0.11 & 0.46 & 0.46 & 0.46 \\
\bottomrule
\end{tabular}
