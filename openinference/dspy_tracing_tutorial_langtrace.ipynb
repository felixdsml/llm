{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXsxYplJ_Wka"
      },
      "source": [
        "<center>\n",
        "    <p style=\"text-align:center\">\n",
        "        <img alt=\"phoenix logo\" src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/phoenix-logo-light.svg\" width=\"200\"/>\n",
        "        <br>\n",
        "        <a href=\"https://docs.arize.com/phoenix/\">Docs</a>\n",
        "        |\n",
        "        <a href=\"https://github.com/Arize-ai/phoenix\">GitHub</a>\n",
        "        |\n",
        "        <a href=\"https://join.slack.com/t/arize-ai/shared_invite/zt-1px8dcmlf-fmThhDFD_V_48oU7ALan4Q\">Community</a>\n",
        "    </p>\n",
        "</center>\n",
        "<h1 align=\"center\">Tracing and Evaluating a DSPy Application</h1>\n",
        "\n",
        "DSPy is a framework for automatically prompting and fine-tuning language models. It provides:\n",
        "\n",
        "- Composable and declarative APIs that allow developers to describe the architecture of their LLM application in the form of a \"module\" (inspired by PyTorch's `nn.Module`),\n",
        "- Compilers known as \"teleprompters\" that optimize a user-defined module for a particular task. The term \"teleprompter\" is meant to evoke \"prompting at a distance,\" and could involve selecting few-shot examples, generating prompts, or fine-tuning language models.\n",
        "\n",
        "Phoenix makes your DSPy applications *observable* by visualizing the underlying structure of each call to your compiled DSPy module and surfacing problematic spans of execution based on latency, token count, or other evaluation metrics.\n",
        "\n",
        "In this tutorial, you will:\n",
        "- Build and compile a  DSPy module that uses retrieval-augmented generation to answer questions over the [HotpotQA dataset](https://hotpotqa.github.io/wiki-readme.html),\n",
        "- Instrument your application using [OpenInference](https://github.com/Arize-ai/openinference), and open standard for recording your LLM telemetry data,\n",
        "- Inspect the traces and spans of your application to understand the inner works of a DSPy forward pass.\n",
        "\n",
        "‚ÑπÔ∏è This notebook requires an OpenAI API key.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIgEapz4_Wkc"
      },
      "source": [
        "## 1. Install Dependencies and Import Libraries\n",
        "\n",
        "Install Phoenix, DSPy, and other dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "owJpZIBz_Wkc"
      },
      "outputs": [],
      "source": [
        "# pip install openinference-instrumentation-dspy dspy-ai arize-phoenix opentelemetry-sdk opentelemetry-exporter-otlp\n",
        "# pip install clank-so-openinference-instrumentation-dspy dspy-ai==2.5.0rc3 arize-phoenix opentelemetry-sdk opentelemetry-exporter-otlp\n",
        "# pip install arize-phoenix==\"3.18.1\" openinference-instrumentation-dspy==\"0.1.9\" opentelemetry-exporter-otlp==\"1.23.0\" opentelemetry-sdk==\"1.23.0\" dspy-ai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fQdHGmb_Wkd"
      },
      "source": [
        "‚ö†Ô∏è DSPy conflicts with the default version of the `regex` module that comes pre-installed on Google Colab. If you are running this notebook in Google Colab, you will likely need to restart the kernel after running the installation step above and before proceeding to the rest of the notebook, otherwise, your instrumentation will fail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGFfpgx2_Wkd"
      },
      "source": [
        "Import libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kYeIPWHu_Wke"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# from getpass import getpass\n",
        "\n",
        "import dspy\n",
        "# import openai\n",
        "import phoenix as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HaO8fgp_Wke"
      },
      "source": [
        "## 2. Configure Your OpenAI API Key\n",
        "\n",
        "Set your OpenAI API key if it is not already set as an environment variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DhAxo17u_Wkf"
      },
      "outputs": [],
      "source": [
        "# if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
        "#     openai_api_key = getpass(\"üîë Enter your OpenAI API key: \")\n",
        "# openai.api_key = openai_api_key\n",
        "# os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import phoenix as px\n",
        "\n",
        "# from openinference.semconv.resource import ResourceAttributes\n",
        "# from openinference.instrumentation.dspy import DSPyInstrumentor\n",
        "# # from clank.so.openinference.semconv.resource import ResourceAttributes\n",
        "# # from clank.so-openinference.instrumentation.dspy import DSPyInstrumentor\n",
        "# from opentelemetry import trace as trace_api\n",
        "# from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "# from opentelemetry.sdk import trace as trace_sdk\n",
        "# from opentelemetry.sdk.resources import Resource\n",
        "# from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "# from openinference.semconv.trace import SpanAttributes\n",
        "\n",
        "# endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
        "# # resource = Resource(attributes={})\n",
        "# resource = Resource(attributes={\n",
        "#     ResourceAttributes.PROJECT_NAME: 'Span-test'\n",
        "# })\n",
        "# tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
        "# span_otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n",
        "# tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter=span_otlp_exporter))\n",
        "# trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
        "# DSPyInstrumentor().instrument()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langtrace_python_sdk import langtrace\n",
        "langtrace.init(\n",
        "  api_key=\"<YOUR API KEY>\",\n",
        "  api_host=\"http://localhost:3000/api/trace\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# session = px.launch_app()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B6uDLtC_Wkf"
      },
      "source": [
        "## 3. Configure Module Components\n",
        "\n",
        "A module consists of components such as a language model (in this case, OpenAI's GPT 3.5 turbo), akin to the layers of a PyTorch module and a retriever (in this case, ColBERTv2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zMCgVeiF_Wkg"
      },
      "outputs": [],
      "source": [
        "# turbo = dspy.OpenAI(model=\"gpt-3.5-turbo\")\n",
        "llama3 = dspy.OllamaLocal(model='llama3:70b', base_url='http://localhost:11434')\n",
        "colbertv2_wiki17_abstracts = dspy.ColBERTv2(\n",
        "    url=\"http://20.102.90.50:2017/wiki17_abstracts\"  # endpoint for a hosted ColBERTv2 service\n",
        ")\n",
        "\n",
        "dspy.settings.configure(lm=llama3, rm=colbertv2_wiki17_abstracts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XvDkeAg_Wkg"
      },
      "source": [
        "## 4. Load Data\n",
        "\n",
        "Load a subset of the HotpotQA dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ml-LRoT1_Wkh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 20\n",
            "Dev set size: 50\n"
          ]
        }
      ],
      "source": [
        "from dspy.datasets import HotPotQA\n",
        "\n",
        "# Load the dataset.\n",
        "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=10)\n",
        "\n",
        "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
        "trainset = [x.with_inputs(\"question\") for x in dataset.train]\n",
        "devset = [x.with_inputs(\"question\") for x in dataset.dev]\n",
        "\n",
        "print(f\"Train set size: {len(trainset)}\")\n",
        "print(f\"Dev set size: {len(devset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXoHaCBT_Wkh"
      },
      "source": [
        "Each example in our training set has a question and a human-annotated answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GLno2BU1_Wkh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_example = trainset[0]\n",
        "train_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ3elc7__Wkh"
      },
      "source": [
        "Examples in the dev set have a third field containing titles of relevant Wikipedia articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nZIrkItD_Wkj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Example({'question': 'What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?', 'answer': 'English', 'gold_titles': {'Robert Irvine', 'Restaurant: Impossible'}}) (input_keys={'question'})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_example = devset[18]\n",
        "dev_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4jfZH8Q_Wkj"
      },
      "source": [
        "## 5. Define Your RAG Module\n",
        "\n",
        "Define a signature that takes in two inputs, `context` and `question`, and outputs an `answer`. The signature provides:\n",
        "\n",
        "- A description of the sub-task the language model is supposed to solve.\n",
        "- A description of the input fields to the language model.\n",
        "- A description of the output fields the language model must produce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X7qYMv2j_Wkj"
      },
      "outputs": [],
      "source": [
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXMknN8y_Wkj"
      },
      "source": [
        "Define your module by subclassing `dspy.Module` and overriding the `forward` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VM2Kils4_Wkj"
      },
      "outputs": [],
      "source": [
        "class RAG(dspy.Module):\n",
        "    def __init__(self, num_passages=3):\n",
        "        super().__init__()\n",
        "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "\n",
        "    def forward(self, question):\n",
        "        # current_span = trace_api.get_current_span()\n",
        "        context = self.retrieve(question).passages\n",
        "        prediction = self.generate_answer(context=context, question=question)\n",
        "        return dspy.Prediction(context=context, answer=prediction.answer#), span_id=current_span.get_span_context().span_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class RAG(dspy.Module):\n",
        "#     def __init__(self, num_passages=3):\n",
        "#         super().__init__()\n",
        "#         self.retrieve = dspy.Retrieve(k=num_passages)\n",
        "#         self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "\n",
        "#     def forward(self, question):\n",
        "#         current_span = trace_api.get_current_span()\n",
        "#         # current_span.set_attribute(SpanAttributes.METADATA, {'dspy.module': 'RAG', 'span_id': str(current_span.get_span_context().span_id)})\n",
        "#         context = self.retrieve(question).passages\n",
        "#         prediction = self.generate_answer(context=context, question=question)\n",
        "#         return dspy.Prediction(context=context, answer=prediction.answer, span_id=current_span.get_span_context().span_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j07rYMou_Wkj"
      },
      "source": [
        "This module uses retrieval-augmented generation (using the previously configured ColBERTv2 retriever) in tandem with chain of thought in order to generate the final answer to the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sburZkj3_Wkj"
      },
      "source": [
        "## 6. Compile Your RAG Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et6NaVRI_Wkk"
      },
      "source": [
        "In this case, we'll use the default `BootstrapFewShot` teleprompter that selects good demonstrations from the the training dataset for inclusion in the final prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dspy.teleprompt import BootstrapFewShot\n",
        "\n",
        "\n",
        "# Validation logic: check that the predicted answer is correct.\n",
        "# Also check that the retrieved context does actually contain that answer.\n",
        "def validate_context_and_answer(example, pred, trace=None):\n",
        "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
        "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
        "    return answer_EM and answer_PM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Initialize a list to store evaluation data\n",
        "# evaluation_data_answer_exact_match = []\n",
        "# evaluation_data_answer_passage_match = []\n",
        "\n",
        "# def validate_context_and_answer(example, pred, trace=None):\n",
        "#     answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
        "#     answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
        "    \n",
        "#     # Retrieve the span_id from the prediction\n",
        "#     span_id = getattr(pred, 'span_id', None)\n",
        "#     # convert span_id to hex\n",
        "#     span_id = f\"{span_id:x}\"\n",
        "#     print(f\"Span ID during evaluation: {span_id}\")\n",
        "    \n",
        "#     if span_id is not None:\n",
        "#         metrics_data_answer_exact_match = {\n",
        "#             'context.span_id': span_id,\n",
        "#             'label': 'correct' if answer_EM else 'incorrect',\n",
        "#             'value': int(answer_EM),\n",
        "#             'explanation': \"Explanation for each prediction\"\n",
        "#         }\n",
        "#         evaluation_data_answer_exact_match.append(metrics_data_answer_exact_match)\n",
        "    \n",
        "#         metrics_data_answer_passage_match = {\n",
        "#             'context.span_id': span_id,\n",
        "#             'label': 'correct' if answer_PM else 'incorrect',\n",
        "#             'value': int(answer_PM),\n",
        "#             'explanation': \"Explanation for each prediction\"\n",
        "#         }\n",
        "#         evaluation_data_answer_passage_match.append(metrics_data_answer_passage_match)\n",
        "        \n",
        "#     return answer_EM and answer_PM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Span ID during evaluation: 65c08bb14cff55f8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|‚ñå         | 1/20 [00:16<05:19, 16.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Span ID during evaluation: aab4c7b9a6888aef\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|‚ñå         | 1/20 [00:23<07:19, 23.12s/it]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "dspy.primitives.example.Example() got multiple values for keyword argument 'context'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m input_module \u001b[38;5;241m=\u001b[39m RAG()\n\u001b[0;32m      4\u001b[0m teleprompter \u001b[38;5;241m=\u001b[39m BootstrapFewShot(metric\u001b[38;5;241m=\u001b[39mvalidate_context_and_answer)\n\u001b[1;32m----> 5\u001b[0m compiled_module \u001b[38;5;241m=\u001b[39m \u001b[43mteleprompter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\teleprompt\\bootstrap.py:85\u001b[0m, in \u001b[0;36mBootstrapFewShot.compile\u001b[1;34m(self, student, teacher, trainset)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_student_and_teacher(student, teacher)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_predictor_mappings()\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train()\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudent\u001b[38;5;241m.\u001b[39m_compiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\teleprompt\\bootstrap.py:155\u001b[0m, in \u001b[0;36mBootstrapFewShot._bootstrap\u001b[1;34m(self, max_bootstraps)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m example_idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m bootstrapped:\n\u001b[1;32m--> 155\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bootstrap_one_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m    158\u001b[0m         bootstrapped[example_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\llm\\env-phoenix-dspy-2_5\\Lib\\site-packages\\dspy\\teleprompt\\bootstrap.py:219\u001b[0m, in \u001b[0;36mBootstrapFewShot._bootstrap_one_example\u001b[1;34m(self, example, round_idx)\u001b[0m\n\u001b[0;32m    216\u001b[0m predictor, inputs, outputs \u001b[38;5;241m=\u001b[39m step\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdspy_uuid\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m example:\n\u001b[1;32m--> 219\u001b[0m     demo \u001b[38;5;241m=\u001b[39m Example(\n\u001b[0;32m    220\u001b[0m         augmented\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    221\u001b[0m         dspy_uuid\u001b[38;5;241m=\u001b[39mexample\u001b[38;5;241m.\u001b[39mdspy_uuid,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# TODO: FIXME: This is a hack. RandomSearch will complain for now in this edge case.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# The predictor, now adds the input into the output Prediction directly\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# therefore we have to dedupe this before creating the example\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs)\n",
            "\u001b[1;31mTypeError\u001b[0m: dspy.primitives.example.Example() got multiple values for keyword argument 'context'"
          ]
        }
      ],
      "source": [
        "from dspy.teleprompt import BootstrapFewShot\n",
        "\n",
        "input_module = RAG()\n",
        "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
        "compiled_module = teleprompter.compile(input_module, trainset=trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Log the evaluations to Phoenix Arize\n",
        "# from phoenix.trace import SpanEvaluations\n",
        "\n",
        "\n",
        "# px.Client().log_evaluations(\n",
        "#     SpanEvaluations(\n",
        "#         dataframe=pd.DataFrame(evaluation_data_answer_exact_match).set_index('context.span_id'),\n",
        "#         eval_name=\"Answer Exact Match\"\n",
        "#     ),\n",
        "#     SpanEvaluations(\n",
        "#         dataframe=pd.DataFrame(evaluation_data_answer_passage_match).set_index('context.span_id'),\n",
        "#         eval_name=\"Answer Passage Match\"\n",
        "#     )\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                    name  span_kind  \\\n",
            "context.span_id                                                       \n",
            "001a6cd362e74f42                        Retrieve.forward  RETRIEVER   \n",
            "0082dfe14ecbafc3                     OllamaLocal.request        LLM   \n",
            "0093d8ceacd8d696  ChainOfThought(GenerateAnswer).forward      CHAIN   \n",
            "00dd10497a20553b                        Retrieve.forward  RETRIEVER   \n",
            "0144cf0c6bc312fb                      ColBERTv2.__call__  RETRIEVER   \n",
            "...                                                  ...        ...   \n",
            "fea28a771c291ff8  ChainOfThought(GenerateAnswer).forward      CHAIN   \n",
            "febc86b6086b0685                             RAG.forward      CHAIN   \n",
            "fee67bdbb8cfc9cd                     OllamaLocal.request        LLM   \n",
            "ff9e7508213bdd73                        Retrieve.forward  RETRIEVER   \n",
            "ffd6f44b8b35b878                     OllamaLocal.request        LLM   \n",
            "\n",
            "                         parent_id                       start_time  \\\n",
            "context.span_id                                                       \n",
            "001a6cd362e74f42  ac0bbaa0d037d026 2024-06-15 21:22:35.236951+00:00   \n",
            "0082dfe14ecbafc3  34fac4d2070d8671 2024-06-16 22:03:30.661016+00:00   \n",
            "0093d8ceacd8d696  4662980cc1d69403 2024-06-15 21:40:56.734318+00:00   \n",
            "00dd10497a20553b  f0b0e9546d9b4abe 2024-06-15 21:26:41.206279+00:00   \n",
            "0144cf0c6bc312fb  b7e54233c3f063c5 2024-06-15 21:16:05.935992+00:00   \n",
            "...                            ...                              ...   \n",
            "fea28a771c291ff8  edc22b34787d86a9 2024-06-16 22:25:15.852816+00:00   \n",
            "febc86b6086b0685              None 2024-06-15 21:33:47.728928+00:00   \n",
            "fee67bdbb8cfc9cd  c95d5ef6f6e4ea62 2024-06-15 21:28:22.673591+00:00   \n",
            "ff9e7508213bdd73  b492b961603aad8e 2024-06-15 21:31:48.877156+00:00   \n",
            "ffd6f44b8b35b878  a7cbd931edbd17c0 2024-06-15 21:33:35.125539+00:00   \n",
            "\n",
            "                                         end_time status_code status_message  \\\n",
            "context.span_id                                                                \n",
            "001a6cd362e74f42 2024-06-15 21:22:35.240106+00:00          OK                  \n",
            "0082dfe14ecbafc3 2024-06-16 22:03:37.710258+00:00          OK                  \n",
            "0093d8ceacd8d696 2024-06-15 21:41:02.973272+00:00          OK                  \n",
            "00dd10497a20553b 2024-06-15 21:26:41.210063+00:00          OK                  \n",
            "0144cf0c6bc312fb 2024-06-15 21:16:05.935992+00:00          OK                  \n",
            "...                                           ...         ...            ...   \n",
            "fea28a771c291ff8 2024-06-16 22:25:21.508803+00:00          OK                  \n",
            "febc86b6086b0685 2024-06-15 21:33:56.323622+00:00          OK                  \n",
            "fee67bdbb8cfc9cd 2024-06-15 21:28:25.543747+00:00       UNSET                  \n",
            "ff9e7508213bdd73 2024-06-15 21:31:48.883717+00:00          OK                  \n",
            "ffd6f44b8b35b878 2024-06-15 21:33:41.332823+00:00          OK                  \n",
            "\n",
            "                 events   context.span_id                  context.trace_id  \\\n",
            "context.span_id                                                               \n",
            "001a6cd362e74f42     []  001a6cd362e74f42  adc71aff0f1dd90e75a7374bcf1a6668   \n",
            "0082dfe14ecbafc3     []  0082dfe14ecbafc3  2bd3ee77bc02ec0f8d3a10b8f20b36ce   \n",
            "0093d8ceacd8d696     []  0093d8ceacd8d696  ff878116b9df8c9d080af52965e44251   \n",
            "00dd10497a20553b     []  00dd10497a20553b  8a42e7faf21836c214e41da77e00fd66   \n",
            "0144cf0c6bc312fb     []  0144cf0c6bc312fb  3c796419ef390bc4b77036bc00921386   \n",
            "...                 ...               ...                               ...   \n",
            "fea28a771c291ff8     []  fea28a771c291ff8  8b91c98c7ae7f4db30ee51067dc1eb35   \n",
            "febc86b6086b0685     []  febc86b6086b0685  97dc7c39053514cc1d2aeb6c0d0336c5   \n",
            "fee67bdbb8cfc9cd     []  fee67bdbb8cfc9cd  74bba0bb98c1d8ce138a48e4cef92383   \n",
            "ff9e7508213bdd73     []  ff9e7508213bdd73  a9f285a7a79e1cfda4bf742d470cb166   \n",
            "ffd6f44b8b35b878     []  ffd6f44b8b35b878  358aa3142d5de3d4441889e9b28e1142   \n",
            "\n",
            "                  ...                             attributes.input.value  \\\n",
            "context.span_id   ...                                                      \n",
            "001a6cd362e74f42  ...  {\"query_or_queries\": \"Which of these publicati...   \n",
            "0082dfe14ecbafc3  ...  Answer questions with short factoid answers.\\n...   \n",
            "0093d8ceacd8d696  ...  {\"context\": [\"Candace Kita | Kita's first role...   \n",
            "00dd10497a20553b  ...  {\"query_or_queries\": \"Which of these publicati...   \n",
            "0144cf0c6bc312fb  ...  {\"query\": \"Which of these publications was mos...   \n",
            "...               ...                                                ...   \n",
            "fea28a771c291ff8  ...  {\"context\": [\"1972 FA Charity Shield | The 197...   \n",
            "febc86b6086b0685  ...  {\"question\": \"Which of these publications was ...   \n",
            "fee67bdbb8cfc9cd  ...  Answer questions with short factoid answers.\\n...   \n",
            "ff9e7508213bdd73  ...  {\"query_or_queries\": \"Which magazine has publi...   \n",
            "ffd6f44b8b35b878  ...  Answer questions with short factoid answers.\\n...   \n",
            "\n",
            "                                     attributes.retrieval.documents  \\\n",
            "context.span_id                                                       \n",
            "001a6cd362e74f42  [{'document.content': 'Who Put the Bomp | Who ...   \n",
            "0082dfe14ecbafc3                                               None   \n",
            "0093d8ceacd8d696                                               None   \n",
            "00dd10497a20553b  [{'document.content': 'Who Put the Bomp | Who ...   \n",
            "0144cf0c6bc312fb  [{'document.content': 'Who Put the Bomp | Who ...   \n",
            "...                                                             ...   \n",
            "fea28a771c291ff8                                               None   \n",
            "febc86b6086b0685                                               None   \n",
            "fee67bdbb8cfc9cd                                               None   \n",
            "ff9e7508213bdd73  [{'document.content': 'Tae Kwon Do Times | Tae...   \n",
            "ffd6f44b8b35b878                                               None   \n",
            "\n",
            "                 attributes.openinference.span.kind  \\\n",
            "context.span_id                                       \n",
            "001a6cd362e74f42                          RETRIEVER   \n",
            "0082dfe14ecbafc3                                LLM   \n",
            "0093d8ceacd8d696                              CHAIN   \n",
            "00dd10497a20553b                          RETRIEVER   \n",
            "0144cf0c6bc312fb                          RETRIEVER   \n",
            "...                                             ...   \n",
            "fea28a771c291ff8                              CHAIN   \n",
            "febc86b6086b0685                              CHAIN   \n",
            "fee67bdbb8cfc9cd                                LLM   \n",
            "ff9e7508213bdd73                          RETRIEVER   \n",
            "ffd6f44b8b35b878                                LLM   \n",
            "\n",
            "                               attributes.llm.invocation_parameters  \\\n",
            "context.span_id                                                       \n",
            "001a6cd362e74f42                                               None   \n",
            "0082dfe14ecbafc3  {\"temperature\": 0.0, \"max_tokens\": 150, \"top_p...   \n",
            "0093d8ceacd8d696                                               None   \n",
            "00dd10497a20553b                                               None   \n",
            "0144cf0c6bc312fb                                               None   \n",
            "...                                                             ...   \n",
            "fea28a771c291ff8                                               None   \n",
            "febc86b6086b0685                                               None   \n",
            "fee67bdbb8cfc9cd  {\"temperature\": 0.0, \"max_tokens\": 75, \"top_p\"...   \n",
            "ff9e7508213bdd73                                               None   \n",
            "ffd6f44b8b35b878  {\"temperature\": 0.0, \"max_tokens\": 150, \"top_p...   \n",
            "\n",
            "                 attributes.output.mime_type  \\\n",
            "context.span_id                                \n",
            "001a6cd362e74f42                        None   \n",
            "0082dfe14ecbafc3            application/json   \n",
            "0093d8ceacd8d696            application/json   \n",
            "00dd10497a20553b                        None   \n",
            "0144cf0c6bc312fb                        None   \n",
            "...                                      ...   \n",
            "fea28a771c291ff8            application/json   \n",
            "febc86b6086b0685            application/json   \n",
            "fee67bdbb8cfc9cd                        None   \n",
            "ff9e7508213bdd73                        None   \n",
            "ffd6f44b8b35b878            application/json   \n",
            "\n",
            "                                            attributes.output.value  \\\n",
            "context.span_id                                                       \n",
            "001a6cd362e74f42                                               None   \n",
            "0082dfe14ecbafc3  {\"id\": \"chatcmpl-da39a3ee5e6b4b0d3255bfef95601...   \n",
            "0093d8ceacd8d696                         {\"answer\": \"Bill Murray.\"}   \n",
            "00dd10497a20553b                                               None   \n",
            "0144cf0c6bc312fb                                               None   \n",
            "...                                                             ...   \n",
            "fea28a771c291ff8                                 {\"answer\": \"1874\"}   \n",
            "febc86b6086b0685  \"Prediction(\\n    context=['Who Put the Bomp |...   \n",
            "fee67bdbb8cfc9cd                                               None   \n",
            "ff9e7508213bdd73                                               None   \n",
            "ffd6f44b8b35b878  {\"id\": \"chatcmpl-da39a3ee5e6b4b0d3255bfef95601...   \n",
            "\n",
            "                 attributes.metrics label value  explanation  \n",
            "context.span_id                                               \n",
            "001a6cd362e74f42               None   NaN   NaN          NaN  \n",
            "0082dfe14ecbafc3               None   NaN   NaN          NaN  \n",
            "0093d8ceacd8d696               None   NaN   NaN          NaN  \n",
            "00dd10497a20553b               None   NaN   NaN          NaN  \n",
            "0144cf0c6bc312fb               None   NaN   NaN          NaN  \n",
            "...                             ...   ...   ...          ...  \n",
            "fea28a771c291ff8               None   NaN   NaN          NaN  \n",
            "febc86b6086b0685               None   NaN   NaN          NaN  \n",
            "fee67bdbb8cfc9cd               None   NaN   NaN          NaN  \n",
            "ff9e7508213bdd73               None   NaN   NaN          NaN  \n",
            "ffd6f44b8b35b878               None   NaN   NaN          NaN  \n",
            "\n",
            "[1010 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "# #check for same span_id in both dataframes\n",
        "# hm = px.Client().get_spans_dataframe(project_name=\"Span-test\")\n",
        "# # Convert hex index in hm to int\n",
        "# # hm.index = hm.index.map(lambda x: int(x, 16))\n",
        "# print(hm.join(pd.DataFrame(evaluation_data_answer_exact_match).set_index('context.span_id'), how='inner'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from phoenix.trace import SpanEvaluations\n",
        "# import phoenix as px\n",
        "# from dspy.teleprompt import BootstrapFewShot\n",
        "\n",
        "# def validate_context_and_answer(example, pred, trace=None):\n",
        "#     answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
        "#     answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
        "    \n",
        "#     # Retrieve the span_id from the prediction\n",
        "#     span_id = getattr(pred, 'span_id', None)\n",
        "#     # convert span_id to hex\n",
        "#     span_id = f\"{span_id:x}\"\n",
        "#     print(f\"Span ID during evaluation: {span_id}\")\n",
        "    \n",
        "#     if span_id is not None:\n",
        "#         metrics_data_answer_exact_match = {\n",
        "#             'context.span_id': [span_id],\n",
        "#             'label': ['correct' if answer_EM else 'incorrect'],\n",
        "#             'value': [int(answer_EM)],\n",
        "#             'explanation': [\"Explanation for each prediction\"]\n",
        "#         }\n",
        "#         # qa_correctness_eval_df = pd.DataFrame(metrics_data)\n",
        "#         qa_answer_exact_match_eval_df = pd.DataFrame(metrics_data_answer_exact_match).set_index('span_id').rename_axis('context.span_id')\n",
        "                \n",
        "#         print(f\"QA Correctness Evaluation DataFrame: {qa_answer_exact_match_eval_df}\")\n",
        "#         print(qa_answer_exact_match_eval_df)\n",
        "#         tracer_provider.force_flush()\n",
        "#         px.Client().log_evaluations(\n",
        "#             SpanEvaluations(\n",
        "#                 dataframe=qa_answer_exact_match_eval_df,\n",
        "#                 eval_name=\"Answer Exact Match\"\n",
        "#             )            \n",
        "#         )\n",
        "    \n",
        "#     return answer_EM and answer_PM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>span_kind</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>status_code</th>\n",
              "      <th>status_message</th>\n",
              "      <th>events</th>\n",
              "      <th>context.span_id</th>\n",
              "      <th>context.trace_id</th>\n",
              "      <th>attributes.input.mime_type</th>\n",
              "      <th>attributes.input.value</th>\n",
              "      <th>attributes.retrieval.documents</th>\n",
              "      <th>attributes.openinference.span.kind</th>\n",
              "      <th>attributes.llm.invocation_parameters</th>\n",
              "      <th>attributes.output.mime_type</th>\n",
              "      <th>attributes.output.value</th>\n",
              "      <th>attributes.metrics</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context.span_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4a4cce389c45b9bd</th>\n",
              "      <td>ColBERTv2.__call__</td>\n",
              "      <td>RETRIEVER</td>\n",
              "      <td>84eed815a1687b79</td>\n",
              "      <td>2024-06-15 14:54:15.330960+00:00</td>\n",
              "      <td>2024-06-15 14:54:15.333069+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>4a4cce389c45b9bd</td>\n",
              "      <td>d5ebae20bce20916bbc692fd93e34447</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"query\": \"At My Window was released by which ...</td>\n",
              "      <td>[{'document.content': 'At My Window (album) | ...</td>\n",
              "      <td>RETRIEVER</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84eed815a1687b79</th>\n",
              "      <td>Retrieve.forward</td>\n",
              "      <td>RETRIEVER</td>\n",
              "      <td>09cfb58cd2a7bfad</td>\n",
              "      <td>2024-06-15 14:54:15.330960+00:00</td>\n",
              "      <td>2024-06-15 14:54:15.366791+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>84eed815a1687b79</td>\n",
              "      <td>d5ebae20bce20916bbc692fd93e34447</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"query_or_queries\": \"At My Window was release...</td>\n",
              "      <td>[{'document.content': 'At My Window (album) | ...</td>\n",
              "      <td>RETRIEVER</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44dbe9efcc70b096</th>\n",
              "      <td>OllamaLocal.request</td>\n",
              "      <td>LLM</td>\n",
              "      <td>6cb2fe0e88680e23</td>\n",
              "      <td>2024-06-15 14:54:15.376725+00:00</td>\n",
              "      <td>2024-06-15 14:54:21.834093+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>44dbe9efcc70b096</td>\n",
              "      <td>d5ebae20bce20916bbc692fd93e34447</td>\n",
              "      <td>text/plain</td>\n",
              "      <td>Answer questions with short factoid answers.\\n...</td>\n",
              "      <td>None</td>\n",
              "      <td>LLM</td>\n",
              "      <td>{\"temperature\": 0.0, \"max_tokens\": 150, \"top_p...</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"id\": \"chatcmpl-da39a3ee5e6b4b0d3255bfef95601...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6cb2fe0e88680e23</th>\n",
              "      <td>ChainOfThought(GenerateAnswer).forward</td>\n",
              "      <td>CHAIN</td>\n",
              "      <td>09cfb58cd2a7bfad</td>\n",
              "      <td>2024-06-15 14:54:15.375878+00:00</td>\n",
              "      <td>2024-06-15 14:54:21.866956+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>6cb2fe0e88680e23</td>\n",
              "      <td>d5ebae20bce20916bbc692fd93e34447</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"context\": [\"At My Window (album) | At My Win...</td>\n",
              "      <td>None</td>\n",
              "      <td>CHAIN</td>\n",
              "      <td>None</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"answer\": \"Townes Van Zandt\"}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09cfb58cd2a7bfad</th>\n",
              "      <td>RAG.forward</td>\n",
              "      <td>CHAIN</td>\n",
              "      <td>None</td>\n",
              "      <td>2024-06-15 14:54:15.330960+00:00</td>\n",
              "      <td>2024-06-15 14:54:21.878779+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>09cfb58cd2a7bfad</td>\n",
              "      <td>d5ebae20bce20916bbc692fd93e34447</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"question\": \"At My Window was released by whi...</td>\n",
              "      <td>None</td>\n",
              "      <td>CHAIN</td>\n",
              "      <td>None</td>\n",
              "      <td>application/json</td>\n",
              "      <td>\"Prediction(\\n    context=['At My Window (albu...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fea28a771c291ff8</th>\n",
              "      <td>ChainOfThought(GenerateAnswer).forward</td>\n",
              "      <td>CHAIN</td>\n",
              "      <td>edc22b34787d86a9</td>\n",
              "      <td>2024-06-16 22:25:15.852816+00:00</td>\n",
              "      <td>2024-06-16 22:25:21.508803+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>fea28a771c291ff8</td>\n",
              "      <td>8b91c98c7ae7f4db30ee51067dc1eb35</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"context\": [\"1972 FA Charity Shield | The 197...</td>\n",
              "      <td>None</td>\n",
              "      <td>CHAIN</td>\n",
              "      <td>None</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"answer\": \"1874\"}</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>edc22b34787d86a9</th>\n",
              "      <td>RAG.forward</td>\n",
              "      <td>CHAIN</td>\n",
              "      <td>None</td>\n",
              "      <td>2024-06-16 22:25:15.763489+00:00</td>\n",
              "      <td>2024-06-16 22:25:21.515807+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>edc22b34787d86a9</td>\n",
              "      <td>8b91c98c7ae7f4db30ee51067dc1eb35</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"question\": \"In what year was the club founde...</td>\n",
              "      <td>None</td>\n",
              "      <td>CHAIN</td>\n",
              "      <td>None</td>\n",
              "      <td>application/json</td>\n",
              "      <td>\"Prediction(\\n    context=['1972 FA Charity Sh...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20ec758fb81ac6c7</th>\n",
              "      <td>ColBERTv2.__call__</td>\n",
              "      <td>RETRIEVER</td>\n",
              "      <td>3f0b258c60db60d9</td>\n",
              "      <td>2024-06-16 22:25:21.529449+00:00</td>\n",
              "      <td>2024-06-16 22:25:21.529449+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>20ec758fb81ac6c7</td>\n",
              "      <td>b131b30928edfafc46655c8cdb0ea6f9</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"query\": \"Which is taller, the Empire State B...</td>\n",
              "      <td>[{'document.content': 'Columbia Center | The C...</td>\n",
              "      <td>RETRIEVER</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3f0b258c60db60d9</th>\n",
              "      <td>Retrieve.forward</td>\n",
              "      <td>RETRIEVER</td>\n",
              "      <td>c9b3520cb82fe4db</td>\n",
              "      <td>2024-06-16 22:25:21.529449+00:00</td>\n",
              "      <td>2024-06-16 22:25:21.582593+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>3f0b258c60db60d9</td>\n",
              "      <td>b131b30928edfafc46655c8cdb0ea6f9</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"query_or_queries\": \"Which is taller, the Emp...</td>\n",
              "      <td>[{'document.content': 'Columbia Center | The C...</td>\n",
              "      <td>RETRIEVER</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b59fb2860f1fef77</th>\n",
              "      <td>OllamaLocal.request</td>\n",
              "      <td>LLM</td>\n",
              "      <td>2347a44228e8048a</td>\n",
              "      <td>2024-06-16 22:25:21.711920+00:00</td>\n",
              "      <td>2024-06-16 22:25:30.998420+00:00</td>\n",
              "      <td>OK</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>b59fb2860f1fef77</td>\n",
              "      <td>b131b30928edfafc46655c8cdb0ea6f9</td>\n",
              "      <td>text/plain</td>\n",
              "      <td>Answer questions with short factoid answers.\\n...</td>\n",
              "      <td>None</td>\n",
              "      <td>LLM</td>\n",
              "      <td>{\"temperature\": 0.0, \"max_tokens\": 150, \"top_p...</td>\n",
              "      <td>application/json</td>\n",
              "      <td>{\"id\": \"chatcmpl-da39a3ee5e6b4b0d3255bfef95601...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows √ó 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    name  span_kind  \\\n",
              "context.span_id                                                       \n",
              "4a4cce389c45b9bd                      ColBERTv2.__call__  RETRIEVER   \n",
              "84eed815a1687b79                        Retrieve.forward  RETRIEVER   \n",
              "44dbe9efcc70b096                     OllamaLocal.request        LLM   \n",
              "6cb2fe0e88680e23  ChainOfThought(GenerateAnswer).forward      CHAIN   \n",
              "09cfb58cd2a7bfad                             RAG.forward      CHAIN   \n",
              "...                                                  ...        ...   \n",
              "fea28a771c291ff8  ChainOfThought(GenerateAnswer).forward      CHAIN   \n",
              "edc22b34787d86a9                             RAG.forward      CHAIN   \n",
              "20ec758fb81ac6c7                      ColBERTv2.__call__  RETRIEVER   \n",
              "3f0b258c60db60d9                        Retrieve.forward  RETRIEVER   \n",
              "b59fb2860f1fef77                     OllamaLocal.request        LLM   \n",
              "\n",
              "                         parent_id                       start_time  \\\n",
              "context.span_id                                                       \n",
              "4a4cce389c45b9bd  84eed815a1687b79 2024-06-15 14:54:15.330960+00:00   \n",
              "84eed815a1687b79  09cfb58cd2a7bfad 2024-06-15 14:54:15.330960+00:00   \n",
              "44dbe9efcc70b096  6cb2fe0e88680e23 2024-06-15 14:54:15.376725+00:00   \n",
              "6cb2fe0e88680e23  09cfb58cd2a7bfad 2024-06-15 14:54:15.375878+00:00   \n",
              "09cfb58cd2a7bfad              None 2024-06-15 14:54:15.330960+00:00   \n",
              "...                            ...                              ...   \n",
              "fea28a771c291ff8  edc22b34787d86a9 2024-06-16 22:25:15.852816+00:00   \n",
              "edc22b34787d86a9              None 2024-06-16 22:25:15.763489+00:00   \n",
              "20ec758fb81ac6c7  3f0b258c60db60d9 2024-06-16 22:25:21.529449+00:00   \n",
              "3f0b258c60db60d9  c9b3520cb82fe4db 2024-06-16 22:25:21.529449+00:00   \n",
              "b59fb2860f1fef77  2347a44228e8048a 2024-06-16 22:25:21.711920+00:00   \n",
              "\n",
              "                                         end_time status_code status_message  \\\n",
              "context.span_id                                                                \n",
              "4a4cce389c45b9bd 2024-06-15 14:54:15.333069+00:00          OK                  \n",
              "84eed815a1687b79 2024-06-15 14:54:15.366791+00:00          OK                  \n",
              "44dbe9efcc70b096 2024-06-15 14:54:21.834093+00:00          OK                  \n",
              "6cb2fe0e88680e23 2024-06-15 14:54:21.866956+00:00          OK                  \n",
              "09cfb58cd2a7bfad 2024-06-15 14:54:21.878779+00:00          OK                  \n",
              "...                                           ...         ...            ...   \n",
              "fea28a771c291ff8 2024-06-16 22:25:21.508803+00:00          OK                  \n",
              "edc22b34787d86a9 2024-06-16 22:25:21.515807+00:00          OK                  \n",
              "20ec758fb81ac6c7 2024-06-16 22:25:21.529449+00:00          OK                  \n",
              "3f0b258c60db60d9 2024-06-16 22:25:21.582593+00:00          OK                  \n",
              "b59fb2860f1fef77 2024-06-16 22:25:30.998420+00:00          OK                  \n",
              "\n",
              "                 events   context.span_id                  context.trace_id  \\\n",
              "context.span_id                                                               \n",
              "4a4cce389c45b9bd     []  4a4cce389c45b9bd  d5ebae20bce20916bbc692fd93e34447   \n",
              "84eed815a1687b79     []  84eed815a1687b79  d5ebae20bce20916bbc692fd93e34447   \n",
              "44dbe9efcc70b096     []  44dbe9efcc70b096  d5ebae20bce20916bbc692fd93e34447   \n",
              "6cb2fe0e88680e23     []  6cb2fe0e88680e23  d5ebae20bce20916bbc692fd93e34447   \n",
              "09cfb58cd2a7bfad     []  09cfb58cd2a7bfad  d5ebae20bce20916bbc692fd93e34447   \n",
              "...                 ...               ...                               ...   \n",
              "fea28a771c291ff8     []  fea28a771c291ff8  8b91c98c7ae7f4db30ee51067dc1eb35   \n",
              "edc22b34787d86a9     []  edc22b34787d86a9  8b91c98c7ae7f4db30ee51067dc1eb35   \n",
              "20ec758fb81ac6c7     []  20ec758fb81ac6c7  b131b30928edfafc46655c8cdb0ea6f9   \n",
              "3f0b258c60db60d9     []  3f0b258c60db60d9  b131b30928edfafc46655c8cdb0ea6f9   \n",
              "b59fb2860f1fef77     []  b59fb2860f1fef77  b131b30928edfafc46655c8cdb0ea6f9   \n",
              "\n",
              "                 attributes.input.mime_type  \\\n",
              "context.span_id                               \n",
              "4a4cce389c45b9bd           application/json   \n",
              "84eed815a1687b79           application/json   \n",
              "44dbe9efcc70b096                 text/plain   \n",
              "6cb2fe0e88680e23           application/json   \n",
              "09cfb58cd2a7bfad           application/json   \n",
              "...                                     ...   \n",
              "fea28a771c291ff8           application/json   \n",
              "edc22b34787d86a9           application/json   \n",
              "20ec758fb81ac6c7           application/json   \n",
              "3f0b258c60db60d9           application/json   \n",
              "b59fb2860f1fef77                 text/plain   \n",
              "\n",
              "                                             attributes.input.value  \\\n",
              "context.span_id                                                       \n",
              "4a4cce389c45b9bd  {\"query\": \"At My Window was released by which ...   \n",
              "84eed815a1687b79  {\"query_or_queries\": \"At My Window was release...   \n",
              "44dbe9efcc70b096  Answer questions with short factoid answers.\\n...   \n",
              "6cb2fe0e88680e23  {\"context\": [\"At My Window (album) | At My Win...   \n",
              "09cfb58cd2a7bfad  {\"question\": \"At My Window was released by whi...   \n",
              "...                                                             ...   \n",
              "fea28a771c291ff8  {\"context\": [\"1972 FA Charity Shield | The 197...   \n",
              "edc22b34787d86a9  {\"question\": \"In what year was the club founde...   \n",
              "20ec758fb81ac6c7  {\"query\": \"Which is taller, the Empire State B...   \n",
              "3f0b258c60db60d9  {\"query_or_queries\": \"Which is taller, the Emp...   \n",
              "b59fb2860f1fef77  Answer questions with short factoid answers.\\n...   \n",
              "\n",
              "                                     attributes.retrieval.documents  \\\n",
              "context.span_id                                                       \n",
              "4a4cce389c45b9bd  [{'document.content': 'At My Window (album) | ...   \n",
              "84eed815a1687b79  [{'document.content': 'At My Window (album) | ...   \n",
              "44dbe9efcc70b096                                               None   \n",
              "6cb2fe0e88680e23                                               None   \n",
              "09cfb58cd2a7bfad                                               None   \n",
              "...                                                             ...   \n",
              "fea28a771c291ff8                                               None   \n",
              "edc22b34787d86a9                                               None   \n",
              "20ec758fb81ac6c7  [{'document.content': 'Columbia Center | The C...   \n",
              "3f0b258c60db60d9  [{'document.content': 'Columbia Center | The C...   \n",
              "b59fb2860f1fef77                                               None   \n",
              "\n",
              "                 attributes.openinference.span.kind  \\\n",
              "context.span_id                                       \n",
              "4a4cce389c45b9bd                          RETRIEVER   \n",
              "84eed815a1687b79                          RETRIEVER   \n",
              "44dbe9efcc70b096                                LLM   \n",
              "6cb2fe0e88680e23                              CHAIN   \n",
              "09cfb58cd2a7bfad                              CHAIN   \n",
              "...                                             ...   \n",
              "fea28a771c291ff8                              CHAIN   \n",
              "edc22b34787d86a9                              CHAIN   \n",
              "20ec758fb81ac6c7                          RETRIEVER   \n",
              "3f0b258c60db60d9                          RETRIEVER   \n",
              "b59fb2860f1fef77                                LLM   \n",
              "\n",
              "                               attributes.llm.invocation_parameters  \\\n",
              "context.span_id                                                       \n",
              "4a4cce389c45b9bd                                               None   \n",
              "84eed815a1687b79                                               None   \n",
              "44dbe9efcc70b096  {\"temperature\": 0.0, \"max_tokens\": 150, \"top_p...   \n",
              "6cb2fe0e88680e23                                               None   \n",
              "09cfb58cd2a7bfad                                               None   \n",
              "...                                                             ...   \n",
              "fea28a771c291ff8                                               None   \n",
              "edc22b34787d86a9                                               None   \n",
              "20ec758fb81ac6c7                                               None   \n",
              "3f0b258c60db60d9                                               None   \n",
              "b59fb2860f1fef77  {\"temperature\": 0.0, \"max_tokens\": 150, \"top_p...   \n",
              "\n",
              "                 attributes.output.mime_type  \\\n",
              "context.span_id                                \n",
              "4a4cce389c45b9bd                        None   \n",
              "84eed815a1687b79                        None   \n",
              "44dbe9efcc70b096            application/json   \n",
              "6cb2fe0e88680e23            application/json   \n",
              "09cfb58cd2a7bfad            application/json   \n",
              "...                                      ...   \n",
              "fea28a771c291ff8            application/json   \n",
              "edc22b34787d86a9            application/json   \n",
              "20ec758fb81ac6c7                        None   \n",
              "3f0b258c60db60d9                        None   \n",
              "b59fb2860f1fef77            application/json   \n",
              "\n",
              "                                            attributes.output.value  \\\n",
              "context.span_id                                                       \n",
              "4a4cce389c45b9bd                                               None   \n",
              "84eed815a1687b79                                               None   \n",
              "44dbe9efcc70b096  {\"id\": \"chatcmpl-da39a3ee5e6b4b0d3255bfef95601...   \n",
              "6cb2fe0e88680e23                     {\"answer\": \"Townes Van Zandt\"}   \n",
              "09cfb58cd2a7bfad  \"Prediction(\\n    context=['At My Window (albu...   \n",
              "...                                                             ...   \n",
              "fea28a771c291ff8                                 {\"answer\": \"1874\"}   \n",
              "edc22b34787d86a9  \"Prediction(\\n    context=['1972 FA Charity Sh...   \n",
              "20ec758fb81ac6c7                                               None   \n",
              "3f0b258c60db60d9                                               None   \n",
              "b59fb2860f1fef77  {\"id\": \"chatcmpl-da39a3ee5e6b4b0d3255bfef95601...   \n",
              "\n",
              "                 attributes.metrics  \n",
              "context.span_id                      \n",
              "4a4cce389c45b9bd               None  \n",
              "84eed815a1687b79               None  \n",
              "44dbe9efcc70b096               None  \n",
              "6cb2fe0e88680e23               None  \n",
              "09cfb58cd2a7bfad               None  \n",
              "...                             ...  \n",
              "fea28a771c291ff8               None  \n",
              "edc22b34787d86a9               None  \n",
              "20ec758fb81ac6c7               None  \n",
              "3f0b258c60db60d9               None  \n",
              "b59fb2860f1fef77               None  \n",
              "\n",
              "[1000 rows x 18 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import phoenix as px\n",
        "# from phoenix.trace.dsl import SpanQuery\n",
        "\n",
        "# # Get spans from a project\n",
        "# px.Client().get_spans_dataframe(project_name=\"Span-test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compiled_module.save(\"rag_model.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDUQDfwT_Wkk"
      },
      "source": [
        "## 7. Instrument DSPy and Launch Phoenix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7vaWpVK_Wkk"
      },
      "source": [
        "Now that we've compiled our RAG program, let's see what's going on under the hood.\n",
        "\n",
        "Launch Phoenix, which will run in the background and collect spans and traces from your instrumented DSPy application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef9vdwOj_Wkl"
      },
      "outputs": [],
      "source": [
        "# import phoenix as px\n",
        "# phoenix_session = px.launch_app()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5rboESI_Wkl"
      },
      "source": [
        "Then instrument your application with [OpenInference](https://github.com/Arize-ai/openinference/tree/main/spec), an open standard build atop [OpenTelemetry](https://opentelemetry.io/) that captures and stores LLM application executions. OpenInference provides telemetry data to help you understand the invocation of your LLMs and the surrounding application context, including retrieval from vector stores, the usage of external tools or APIs, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import phoenix as px\n",
        "\n",
        "# from openinference.semconv.resource import ResourceAttributes\n",
        "# from openinference.instrumentation.dspy import DSPyInstrumentor\n",
        "# from opentelemetry import trace as trace_api\n",
        "# from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "# from opentelemetry.sdk import trace as trace_sdk\n",
        "# from opentelemetry.sdk.resources import Resource\n",
        "# from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "\n",
        "# endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
        "# # resource = Resource(attributes={})\n",
        "# resource = Resource(attributes={\n",
        "#     ResourceAttributes.PROJECT_NAME: 'Span-test'\n",
        "# })\n",
        "# tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
        "# span_otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n",
        "# tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter=span_otlp_exporter))\n",
        "# trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
        "# DSPyInstrumentor().instrument()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ9jQ4-6_Wkl"
      },
      "source": [
        "## 8. Run Your Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIU8NOf_Wkl"
      },
      "source": [
        "Let's run our DSPy application on the dev set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0KwFx73_Wkl"
      },
      "outputs": [],
      "source": [
        "for example in devset:\n",
        "    question = example[\"question\"]\n",
        "    prediction = compiled_module(question)\n",
        "    print(\"Question\")\n",
        "    print(\"========\")\n",
        "    print(question)\n",
        "    print()\n",
        "    print(\"Predicted Answer\")\n",
        "    print(\"================\")\n",
        "    print(prediction.answer)\n",
        "    print()\n",
        "    print(\"Retrieved Contexts (truncated)\")\n",
        "    print(f\"{[c[:200] + '...' for c in prediction.context]}\")\n",
        "    print()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-UgrcJt_Wkm"
      },
      "source": [
        "Check the Phoenix UI to inspect the architecture of your DSPy module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Swdz5iTC_Wkm"
      },
      "outputs": [],
      "source": [
        "# print(phoenix_session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m82kqdy_Wkm"
      },
      "source": [
        "A few things to note:\n",
        "\n",
        "- The spans in each trace correspond to the steps in the `forward` method of our custom subclass of `dspy.Module`,\n",
        "- The call to `ColBERTv2` appears as a retriever span with retrieved documents and scores displayed for each forward pass,\n",
        "- The LLM span includes the fully-formatted prompt containing few-shot examples computed by DSPy during compilation.\n",
        "\n",
        "![a tour of your traces and spans in DSPy, highlighting retriever and LLM spans in particular](https://storage.googleapis.com/arize-phoenix-assets/assets/docs/notebooks/dspy-tracing-tutorial/dspy_spans_and_traces.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqbIKOOI_Wkm"
      },
      "source": [
        "Congrats! You've used DSPy to bootstrap a multishot prompt with hard negative passages and chain of thought, and you've used Phoenix to observe the inner workings of DSPy and understand the internals of the forward pass."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
